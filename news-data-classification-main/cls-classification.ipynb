{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Text after cleaning:\n"
     ]
    }
   ],
   "source": [
    "# 기본 라이브러리\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 처리 관련\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    BertConfig, AutoTokenizer, BertForSequenceClassification, AdamW\n",
    ")\n",
    "\n",
    "# 평가 관련 (F1 Score, Classification Report)\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "# Config 불러오기\n",
    "import config\n",
    "\n",
    "# 라벨 변환 관련 모듈\n",
    "import label\n",
    "\n",
    "# 데이터셋 관련 모듈\n",
    "import Dataset\n",
    "\n",
    "sys.path.append('/home/lhch9550/공모전/KPF-BERT-CLS')\n",
    "\n",
    "# 데이터 로딩\n",
    "data = pd.read_csv('/home/lhch9550/공모전/KPF-BERT-CLS/processed_data.csv')  \n",
    "print(\"Data loaded!\")\n",
    "\n",
    "# 텍스트 클리닝 함수 정의\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z-.]+)\", \"\", text)  # 이메일 제거\n",
    "    text = re.sub(\"[\\r\\n\\xa0]\", \"\", text)  # 줄 바꿈 및 특수문자 제거\n",
    "    text = re.sub(\"(\\.\\s+[ㄱ-ㅎ가-힣]+\\s[기]+[자]+)\", \"\", text)  # 특정한 문장 패턴 제거\n",
    "    text = re.sub(\"[^\\w\\s^.]\", \" \", text)  # 알파벳, 숫자, 공백을 제외한 문자 제거\n",
    "    return text\n",
    "\n",
    "# 텍스트 전처리 적용\n",
    "data['NEWS_CNTS'] = data['NEWS_CNTS'].apply(clean_text)\n",
    "print(\"Text after cleaning:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존의 소분류 라벨\n",
    "small_label = ['국회_정당', '북한', '선거', '외교', '청와대', '행정_자치', '골프', '농구_배구', '야구_메이저리그',\n",
    "               '야구_일본프로야구', '올림픽_아시안게임', '축구_월드컵', '축구_한국프로축구', '축구_해외축구',\n",
    "               '교육_시험', '날씨', '노동_복지', '미디어', '사건_사고', '여성', '의료_건강', '장애인', '환경',\n",
    "               '미술_건축', '방송_연예', '생활', '요리_여행', '음악', '전시_공연', '종교', '출판', '학술_문화재',\n",
    "               '러시아', '미국_북미', '아시아', '유럽_EU', '일본', '중국', '중남미', '중동_아프리카', '국제경제',\n",
    "               '금융_재테크', '무역', '반도체', '부동산', '산업_기업', '서비스_쇼핑', '외환', '유통', '자동차',\n",
    "               '자원', '증권_증시', '취업_창업', '과학', '모바일', '보안', '인터넷_SNS', '콘텐츠']\n",
    "\n",
    "# 소분류 라벨에 맞춘 label2id, id2label 생성\n",
    "small_label2id = {label: i for i, label in enumerate(small_label)}\n",
    "small_id2label = {i: label for label, i in small_label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>original_topic</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>NEWS_SML_SUBJ_CD</th>\n",
       "      <th>NEWS_CNTS</th>\n",
       "      <th>label_list</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>노컷뉴스 2022년 기사</td>\n",
       "      <td>경남CBS 최호영 기자 최호영</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>20220101</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제&gt;취업_창업</td>\n",
       "      <td>NIRW2300000001.10.1</td>\n",
       "      <td>경남 12월에만 5698명 ‘역대 최다’…29일 연속 세 자릿수 확산</td>\n",
       "      <td>취업_창업</td>\n",
       "      <td>경남 12월에만 5698명  역대 최다  29일 연속 세 자릿수 확산</td>\n",
       "      <td>['취업_창업']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>노컷뉴스 2022년 기사</td>\n",
       "      <td>경남CBS 최호영 기자 최호영</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>20220101</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제&gt;취업_창업</td>\n",
       "      <td>NIRW2300000001.10.2</td>\n",
       "      <td>지난해 12월 경남에서 발생한 코로나19 확진자는 역대 가장 많은 5700명에 달했다.</td>\n",
       "      <td>취업_창업</td>\n",
       "      <td>지난해 12월 경남에서 발생한 코로나19 확진자는 역대 가장 많은 5700명에 달했다.</td>\n",
       "      <td>['취업_창업']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>노컷뉴스 2022년 기사</td>\n",
       "      <td>경남CBS 최호영 기자 최호영</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>20220101</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제&gt;취업_창업</td>\n",
       "      <td>NIRW2300000001.10.3</td>\n",
       "      <td>경남은 1일 오전 10시 기준으로 도내 3개 시에서 21명의 확진자가 발생했다. 창...</td>\n",
       "      <td>취업_창업</td>\n",
       "      <td>경남은 1일 오전 10시 기준으로 도내 3개 시에서 21명의 확진자가 발생했다. 창...</td>\n",
       "      <td>['취업_창업']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>노컷뉴스 2022년 기사</td>\n",
       "      <td>경남CBS 최호영 기자 최호영</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>20220101</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제&gt;취업_창업</td>\n",
       "      <td>NIRW2300000001.10.4</td>\n",
       "      <td>이 중 38%인 8명은 도내 또는 다른 지역 확진자의 접촉자, 8명(38%)은 감염...</td>\n",
       "      <td>취업_창업</td>\n",
       "      <td>이 중 38 인 8명은 도내 또는 다른 지역 확진자의 접촉자  8명 38  은 감염...</td>\n",
       "      <td>['취업_창업']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>노컷뉴스 2022년 기사</td>\n",
       "      <td>경남CBS 최호영 기자 최호영</td>\n",
       "      <td>노컷뉴스</td>\n",
       "      <td>20220101</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제&gt;취업_창업</td>\n",
       "      <td>NIRW2300000001.10.5</td>\n",
       "      <td>기존 집단감염 사례를 보면, 거제 소재 종교시설 관련 확진자는 4명이 추가돼 25명...</td>\n",
       "      <td>취업_창업</td>\n",
       "      <td>기존 집단감염 사례를 보면  거제 소재 종교시설 관련 확진자는 4명이 추가돼 25명...</td>\n",
       "      <td>['취업_창업']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734489</th>\n",
       "      <td>734489</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>머니투데이 2022년 기사</td>\n",
       "      <td>대전=허재구|기자|</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>IT_과학&gt;모바일</td>\n",
       "      <td>NPRW2300000001.31892.7</td>\n",
       "      <td>나아가, 특허청은 올해부터 WIPO와 협의해 고객지원 전문가의 역할을 확대하고 국내...</td>\n",
       "      <td>모바일</td>\n",
       "      <td>나아가  특허청은 올해부터 WIPO와 협의해 고객지원 전문가의 역할을 확대하고 국내...</td>\n",
       "      <td>['모바일']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734490</th>\n",
       "      <td>734490</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>머니투데이 2022년 기사</td>\n",
       "      <td>대전=허재구|기자|</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>IT_과학&gt;모바일</td>\n",
       "      <td>NPRW2300000001.31892.8</td>\n",
       "      <td>앞으로 고객지원 전문가는 출원인, 특허사무소 대리인과 긴밀한 소통을 통해 ePCT ...</td>\n",
       "      <td>모바일</td>\n",
       "      <td>앞으로 고객지원 전문가는 출원인  특허사무소 대리인과 긴밀한 소통을 통해 ePCT ...</td>\n",
       "      <td>['모바일']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734491</th>\n",
       "      <td>734491</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>머니투데이 2022년 기사</td>\n",
       "      <td>대전=허재구|기자|</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>IT_과학&gt;모바일</td>\n",
       "      <td>NPRW2300000001.31892.9</td>\n",
       "      <td>이처럼 WIPO가 한국에 고객지원 전문가를 배치하고, 사용자 지원을 더욱 강화하기로...</td>\n",
       "      <td>모바일</td>\n",
       "      <td>이처럼 WIPO가 한국에 고객지원 전문가를 배치하고  사용자 지원을 더욱 강화하기로...</td>\n",
       "      <td>['모바일']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734492</th>\n",
       "      <td>734492</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>머니투데이 2022년 기사</td>\n",
       "      <td>대전=허재구|기자|</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>IT_과학&gt;모바일</td>\n",
       "      <td>NPRW2300000001.31892.10</td>\n",
       "      <td>실제로 지난해 우리나라의 PCT 국제특허 출원은 전년 동기 대비 3.2% 증가한 2...</td>\n",
       "      <td>모바일</td>\n",
       "      <td>실제로 지난해 우리나라의 PCT 국제특허 출원은 전년 동기 대비 3.2  증가한 2...</td>\n",
       "      <td>['모바일']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734493</th>\n",
       "      <td>734493</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>머니투데이 2022년 기사</td>\n",
       "      <td>대전=허재구|기자|</td>\n",
       "      <td>머니투데이</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>IT_과학&gt;모바일</td>\n",
       "      <td>NPRW2300000001.31892.11</td>\n",
       "      <td>김기범 특허청 정보고객지원국장은 “기존 PCT-SAFE 사용자들이 더욱 편리하고 안...</td>\n",
       "      <td>모바일</td>\n",
       "      <td>김기범 특허청 정보고객지원국장은  기존 PCT SAFE 사용자들이 더욱 편리하고 안...</td>\n",
       "      <td>['모바일']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487662 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         file_id                doc_id           title  \\\n",
       "0                0  NIRW2300000001     NIRW2300000001.10   노컷뉴스 2022년 기사   \n",
       "1                1  NIRW2300000001     NIRW2300000001.10   노컷뉴스 2022년 기사   \n",
       "2                2  NIRW2300000001     NIRW2300000001.10   노컷뉴스 2022년 기사   \n",
       "3                3  NIRW2300000001     NIRW2300000001.10   노컷뉴스 2022년 기사   \n",
       "4                4  NIRW2300000001     NIRW2300000001.10   노컷뉴스 2022년 기사   \n",
       "...            ...             ...                   ...             ...   \n",
       "734489      734489  NPRW2300000001  NPRW2300000001.31892  머니투데이 2022년 기사   \n",
       "734490      734490  NPRW2300000001  NPRW2300000001.31892  머니투데이 2022년 기사   \n",
       "734491      734491  NPRW2300000001  NPRW2300000001.31892  머니투데이 2022년 기사   \n",
       "734492      734492  NPRW2300000001  NPRW2300000001.31892  머니투데이 2022년 기사   \n",
       "734493      734493  NPRW2300000001  NPRW2300000001.31892  머니투데이 2022년 기사   \n",
       "\n",
       "                  author publisher      date  topic original_topic  \\\n",
       "0       경남CBS 최호영 기자 최호영      노컷뉴스  20220101     사회       경제>취업_창업   \n",
       "1       경남CBS 최호영 기자 최호영      노컷뉴스  20220101     사회       경제>취업_창업   \n",
       "2       경남CBS 최호영 기자 최호영      노컷뉴스  20220101     사회       경제>취업_창업   \n",
       "3       경남CBS 최호영 기자 최호영      노컷뉴스  20220101     사회       경제>취업_창업   \n",
       "4       경남CBS 최호영 기자 최호영      노컷뉴스  20220101     사회       경제>취업_창업   \n",
       "...                  ...       ...       ...    ...            ...   \n",
       "734489        대전=허재구|기자|     머니투데이  20220628  IT/과학      IT_과학>모바일   \n",
       "734490        대전=허재구|기자|     머니투데이  20220628  IT/과학      IT_과학>모바일   \n",
       "734491        대전=허재구|기자|     머니투데이  20220628  IT/과학      IT_과학>모바일   \n",
       "734492        대전=허재구|기자|     머니투데이  20220628  IT/과학      IT_과학>모바일   \n",
       "734493        대전=허재구|기자|     머니투데이  20220628  IT/과학      IT_과학>모바일   \n",
       "\n",
       "                    sentence_id  \\\n",
       "0           NIRW2300000001.10.1   \n",
       "1           NIRW2300000001.10.2   \n",
       "2           NIRW2300000001.10.3   \n",
       "3           NIRW2300000001.10.4   \n",
       "4           NIRW2300000001.10.5   \n",
       "...                         ...   \n",
       "734489   NPRW2300000001.31892.7   \n",
       "734490   NPRW2300000001.31892.8   \n",
       "734491   NPRW2300000001.31892.9   \n",
       "734492  NPRW2300000001.31892.10   \n",
       "734493  NPRW2300000001.31892.11   \n",
       "\n",
       "                                                 sentence NEWS_SML_SUBJ_CD  \\\n",
       "0                  경남 12월에만 5698명 ‘역대 최다’…29일 연속 세 자릿수 확산            취업_창업   \n",
       "1        지난해 12월 경남에서 발생한 코로나19 확진자는 역대 가장 많은 5700명에 달했다.            취업_창업   \n",
       "2       경남은 1일 오전 10시 기준으로 도내 3개 시에서 21명의 확진자가 발생했다. 창...            취업_창업   \n",
       "3       이 중 38%인 8명은 도내 또는 다른 지역 확진자의 접촉자, 8명(38%)은 감염...            취업_창업   \n",
       "4       기존 집단감염 사례를 보면, 거제 소재 종교시설 관련 확진자는 4명이 추가돼 25명...            취업_창업   \n",
       "...                                                   ...              ...   \n",
       "734489  나아가, 특허청은 올해부터 WIPO와 협의해 고객지원 전문가의 역할을 확대하고 국내...              모바일   \n",
       "734490  앞으로 고객지원 전문가는 출원인, 특허사무소 대리인과 긴밀한 소통을 통해 ePCT ...              모바일   \n",
       "734491  이처럼 WIPO가 한국에 고객지원 전문가를 배치하고, 사용자 지원을 더욱 강화하기로...              모바일   \n",
       "734492  실제로 지난해 우리나라의 PCT 국제특허 출원은 전년 동기 대비 3.2% 증가한 2...              모바일   \n",
       "734493  김기범 특허청 정보고객지원국장은 “기존 PCT-SAFE 사용자들이 더욱 편리하고 안...              모바일   \n",
       "\n",
       "                                                NEWS_CNTS label_list  label  \n",
       "0                  경남 12월에만 5698명  역대 최다  29일 연속 세 자릿수 확산  ['취업_창업']   52.0  \n",
       "1        지난해 12월 경남에서 발생한 코로나19 확진자는 역대 가장 많은 5700명에 달했다.  ['취업_창업']   52.0  \n",
       "2       경남은 1일 오전 10시 기준으로 도내 3개 시에서 21명의 확진자가 발생했다. 창...  ['취업_창업']   52.0  \n",
       "3       이 중 38 인 8명은 도내 또는 다른 지역 확진자의 접촉자  8명 38  은 감염...  ['취업_창업']   52.0  \n",
       "4       기존 집단감염 사례를 보면  거제 소재 종교시설 관련 확진자는 4명이 추가돼 25명...  ['취업_창업']   52.0  \n",
       "...                                                   ...        ...    ...  \n",
       "734489  나아가  특허청은 올해부터 WIPO와 협의해 고객지원 전문가의 역할을 확대하고 국내...    ['모바일']   54.0  \n",
       "734490  앞으로 고객지원 전문가는 출원인  특허사무소 대리인과 긴밀한 소통을 통해 ePCT ...    ['모바일']   54.0  \n",
       "734491  이처럼 WIPO가 한국에 고객지원 전문가를 배치하고  사용자 지원을 더욱 강화하기로...    ['모바일']   54.0  \n",
       "734492  실제로 지난해 우리나라의 PCT 국제특허 출원은 전년 동기 대비 3.2  증가한 2...    ['모바일']   54.0  \n",
       "734493  김기범 특허청 정보고객지원국장은  기존 PCT SAFE 사용자들이 더욱 편리하고 안...    ['모바일']   54.0  \n",
       "\n",
       "[487662 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 변환 함수 정의\n",
    "def label_to_id(label):\n",
    "    \"\"\"쉼표로 구분된 첫 번째 라벨만 선택하고, 해당 라벨을 label2id로 변환\"\"\"\n",
    "    first_label = label.split(',')[0].strip()  # 쉼표로 구분된 첫 번째 라벨만 선택\n",
    "    \n",
    "    if first_label in small_label2id:\n",
    "        return small_label2id[first_label]  # 해당 라벨을 ID로 변환\n",
    "    else:\n",
    "        #print(f\"Label '{first_label}' not found in label2id.\")  # 디버깅 메시지\n",
    "        return None  # 라벨이 없으면 None 반환\n",
    "\n",
    "# 'NEWS_SML_SUBJ_CD' 컬럼을 기준으로 라벨을 숫자 ID로 변환\n",
    "data['label'] = data['NEWS_SML_SUBJ_CD'].apply(label_to_id)\n",
    "\n",
    "# NaN 값이 있는 행을 드랍\n",
    "data = data.dropna(subset=['label'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 데이터 샘플링 함수\n",
    "def sampling_func(data, sample_pct, _seed):\n",
    "    np.random.seed(_seed)\n",
    "    N = len(data)  # 데이터 길이\n",
    "    sample_n = int(N * sample_pct)  # 샘플링할 데이터 수\n",
    "    # DataFrame에서 무작위로 샘플링\n",
    "    sample = data.sample(n=sample_n, random_state=_seed)  # pandas sample 사용\n",
    "    return sample\n",
    "\n",
    "# ClsDataset 클래스 정의\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # 샘플링된 데이터\n",
    "        # 데이터에서 'NEWS_CNTS'와 'label'을 분리\n",
    "        self.texts = data['NEWS_CNTS'].tolist()  # DataFrame에서 텍스트 컬럼 가져오기\n",
    "        self.labels = data['label'].tolist()  # DataFrame에서 라벨 컬럼 가져오기\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 텍스트와 라벨을 반환\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label\n",
    "\n",
    "# 수정된 load_dataset 함수\n",
    "def load_dataset(data, con):\n",
    "    # 결측값 처리: 'label' 컬럼에 NaN 값이 있는 행은 제거\n",
    "    data = data.dropna(subset=['label'])\n",
    "    \n",
    "    # 'label' 컬럼에 NaN 처리 및 정수 값 변환\n",
    "    data['label'] = data['label'].apply(lambda x: int(x) if isinstance(x, (int, float)) else 0)\n",
    "    \n",
    "    # num_labels로 설정한 범위 내로 라벨 값 제한 (예: 0에서 num_labels-1 사이)\n",
    "    data['label'] = data['label'].apply(lambda x: max(0, min(x, con.num_labels - 1)))\n",
    "\n",
    "    # 샘플링 비율 조정: train, valid, test 분할\n",
    "    train_pct = 0.7  # train 비율\n",
    "    valid_pct = 0.2  # valid 비율\n",
    "    test_pct = 0.1   # test 비율\n",
    "\n",
    "    # 데이터에서 'train', 'valid', 'test'로 분할\n",
    "    train_data = data.groupby('label', group_keys=False).apply(sampling_func, sample_pct=train_pct, _seed=con.seed)\n",
    "    train_data.sort_index()\n",
    "\n",
    "    # valid 데이터는 train 데이터를 제외한 나머지에서 샘플링\n",
    "    last_data = data.loc[~data.index.isin(train_data.index)].reset_index(drop=True)\n",
    "    valid_data = last_data.groupby('label', group_keys=False).apply(sampling_func, sample_pct=valid_pct/(valid_pct + test_pct), _seed=con.seed)\n",
    "\n",
    "    # test 데이터는 valid 데이터를 제외한 나머지에서 추출\n",
    "    test_data = last_data.loc[~last_data.index.isin(valid_data.index)].reset_index(drop=True)\n",
    "\n",
    "    # 각 데이터셋 크기 출력 (디버깅용)\n",
    "    print(f\"Train data size: {len(train_data)}\")\n",
    "    print(f\"Valid data size: {len(valid_data)}\")\n",
    "    print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "    # DataLoader 준비\n",
    "    train_dataset = ClsDataset(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=con.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    valid_dataset = ClsDataset(valid_data)\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=con.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    test_dataset = ClsDataset(test_data)\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=con.batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import BertConfig, BertForSequenceClassification, AutoTokenizer, AdamW\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config 클래스를 통해 설정값을 가져옵니다.\n",
    "from config import Config\n",
    "_config = Config()\n",
    "_config.num_labels = len(data['label'].unique())  # 라벨의 고유 개수를 설정\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "def initialize_model(con, label2id):\n",
    "    model = BertForSequenceClassification.from_pretrained(con.model_name, num_labels=len(small_label2id),ignore_mismatched_sizes=True)\n",
    "    model.to(con.device)  # 모델을 GPU로 이동\n",
    "    tokenizer = AutoTokenizer.from_pretrained(con.model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# 옵티마이저 설정\n",
    "def set_optimizer(model, con):\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': model.bert.parameters(), 'lr': 3e-5},\n",
    "        {'params': model.classifier.parameters(), 'lr': con.learning_rate}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=con.learning_rate, eps=con.adam_epsilon, no_deprecation_warning=True)\n",
    "    return optimizer\n",
    "\n",
    "# 학습, 평가, 테스트 에포크 함수\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train_epoch에 tqdm 적용\n",
    "def train_epoch(epoch, model, dataloader, optimizer, tokenizer, con):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} Training\", unit=\"batch\")  \n",
    "\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        text_inputs = [str(text) if isinstance(text, (str, int, float)) else \"\" for text in batch[0]]\n",
    "\n",
    "        sample = tokenizer(\n",
    "            text_inputs, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=con.max_seq_len, \n",
    "            return_tensors=\"pt\", \n",
    "            return_token_type_ids=False, \n",
    "            return_attention_mask=True,  # \n",
    "            return_offsets_mapping=False\n",
    "        )['input_ids']\n",
    "\n",
    "        _label = batch[1].to(con.device)\n",
    "        samples = sample.to(con.device)\n",
    "        labels = torch.tensor(_label).to(con.device)  #\n",
    "\n",
    "        outputs = model(samples, labels=labels)\n",
    "        loss = outputs.loss  # \n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), con.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def valid_epoch(epoch, dataloader, model, tokenizer, con, id2label):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_len = 0\n",
    "    model.eval()\n",
    "    all_token_predictions = []\n",
    "    all_token_labels = []\n",
    "    \n",
    "    tepoch = tqdm(dataloader, unit=\"batch\", leave=False)\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(f\"Valid\")\n",
    "        with torch.no_grad():\n",
    "            sample = tokenizer(batch[0], padding='max_length', truncation=True, stride=con.stride,\n",
    "                               max_length=con.max_seq_len, return_tensors=\"pt\")['input_ids']\n",
    "            _label = batch[1].to(con.device)\n",
    "            samples = sample.to(con.device)\n",
    "            labels = torch.tensor(_label).to(con.device)\n",
    "\n",
    "            outputs = model(samples, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            all_token_labels.extend(labels.cpu().numpy())\n",
    "            all_token_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        tepoch.set_postfix(loss=loss.mean().item())\n",
    "    \n",
    "    # F1 Score 계산\n",
    "    all_token_labels = [id2label[int(x)] for x in all_token_labels]\n",
    "    all_token_predictions = [id2label[int(x)] for x in all_token_predictions]\n",
    "    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"micro\")\n",
    "    print('[Epoch {}] -> F1_score: {:.4f}, Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, token_f1, total_loss / len(dataloader), total_correct / total_len))\n",
    "    \n",
    "    return total_loss / len(dataloader), token_f1\n",
    "\n",
    "def test_epoch(dataloader, model, tokenizer, con, id2label):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_len = 0\n",
    "    model.eval()\n",
    "    all_token_predictions = []\n",
    "    all_token_labels = []\n",
    "    \n",
    "    tepoch = tqdm(dataloader, unit=\"batch\", leave=False)\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(f\"Test\")\n",
    "        with torch.no_grad():\n",
    "            sample = tokenizer(batch[0], padding='max_length', truncation=True, stride=con.stride,\n",
    "                               max_length=con.max_seq_len, return_tensors=\"pt\")['input_ids']\n",
    "            _label = batch[1].to(con.device)\n",
    "            samples = sample.to(con.device)\n",
    "            labels = torch.tensor(_label).to(con.device)\n",
    "            \n",
    "            outputs = model(samples, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            all_token_labels.extend(labels.cpu().numpy())\n",
    "            all_token_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        tepoch.set_postfix(loss=loss.mean().item())\n",
    "    \n",
    "    # F1 Score 계산 및 보고서 출력\n",
    "    all_token_labels = [id2label[int(x)] for x in all_token_labels]\n",
    "    all_token_predictions = [id2label[int(x)] for x in all_token_predictions]\n",
    "    token_result = classification_report(all_token_labels, all_token_predictions)\n",
    "    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"micro\")\n",
    "\n",
    "    print(token_result)\n",
    "    tepoch.set_postfix(loss=total_loss / len(dataloader), token_f1=token_f1)\n",
    "\n",
    "    return total_loss / len(dataloader), token_f1\n",
    "\n",
    "# 학습 과정\n",
    "def train(model, tokenizer, train_dataloader, valid_dataloader, test_dataloader, optimizer, con, small_id2label):\n",
    "    for epoch in range(con.epoch):\n",
    "        print(f\"Epoch {epoch+1}/{con.epoch}\")\n",
    "        \n",
    "        # 학습\n",
    "        train_loss = train_epoch(epoch, model, train_dataloader, optimizer, tokenizer, con)\n",
    "\n",
    "        # 검증\n",
    "        valid_loss, valid_f1 = valid_epoch(epoch, valid_dataloader, model, tokenizer, con, small_id2label)\n",
    "\n",
    "        # 테스트\n",
    "        test_loss, test_f1 = test_epoch(test_dataloader, model, tokenizer, con, small_id2label)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Summary:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "        print(f\"Valid F1: {valid_f1:.4f}, Test F1: {test_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/lhch9550/공모전/KPF-BERT-CLS/cls_model and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([58, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([58]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 341343\n",
      "Valid data size: 97533\n",
      "Test data size: 48786\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화 및 DataLoader 설정\n",
    "model, tokenizer = initialize_model(_config, small_label2id)\n",
    "optimizer = set_optimizer(model, _config)\n",
    "\n",
    "# 데이터셋 준비\n",
    "train_dataloader, valid_dataloader, test_dataloader = load_dataset(data, _config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 호출\n",
    "train(model, tokenizer, train_dataloader, valid_dataloader, test_dataloader, optimizer, _config, small_id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at: /home/lhch9550/공모전/KPF-BERT-CLS/saved_model\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, tokenizer, save_path):\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    print(f\"Model saved at: {save_path}\")\n",
    "\n",
    "# 모델 저장 경로\n",
    "save_path = \"/home/lhch9550/공모전/KPF-BERT-CLS/saved_model\"\n",
    "\n",
    "# 모델 저장 실행\n",
    "save_model(model, tokenizer, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 11872/11872 [02:33<00:00, 77.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 샘플 데이터 정렬 검증\n",
      "\n",
      "📝 Text: 오 시장은  우선 주택공급 정상화를 위한 제도적 기반을 완비하고 신속통합기획을 적용한 재개발 재건축 사업을 조속히 추진하겠다 며  노후 저층 주거지역을 묶는 소규모 주택정비사업인 모아주택  모아타운도 더욱 활성화하겠다 고 말했다.\n",
      "✅ True Label: 부동산\n",
      "🔮 Predicted Label: 러시아\n",
      "\n",
      "📝 Text: 러시아 언론 스포츠 익스프레스에 따르면 팬들이  범인 으로 특정한 선수는 다름 아닌 러시아올림픽위원회 ROC 의 안드레이 모잘레프다.\n",
      "✅ True Label: 올림픽_아시안게임\n",
      "🔮 Predicted Label: 러시아\n",
      "\n",
      "📝 Text: 옐런 장관은 현재 미 재무장관직을 수행중이지만  미 연준 이사와 샌프란시스코 연방은행 총재  연준 이사회 부의장을 거쳐 연준 이사회 의장을 지낸 이력을 가지고 있다.\n",
      "✅ True Label: 외교\n",
      "🔮 Predicted Label: 외교\n",
      "\n",
      "📝 Text: 경남 거창군은 13일부터 22일까지 열흘 간 거창창포원 일원에서  제3회 아리미아 꽃 축제 를 개최한다고 밝혔다.\n",
      "✅ True Label: 요리_여행\n",
      "🔮 Predicted Label: 전시_공연\n",
      "\n",
      "📝 Text: LG엔솔  내일 코스피 상장  따상  성공할까\n",
      "✅ True Label: 증권_증시\n",
      "🔮 Predicted Label: 러시아\n",
      "\n",
      "[Classification Report]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          골프     0.7356    0.8192    0.7752      1311\n",
      "       교육_시험     0.7490    0.5957    0.6636      4323\n",
      "        국제경제     0.0000    0.0000    0.0000      2471\n",
      "       국회_정당     0.5784    0.6919    0.6301     11735\n",
      "      금융_재테크     0.0000    0.0000    0.0000      4892\n",
      "          날씨     0.8525    0.7553    0.8010       421\n",
      "       노동_복지     0.5797    0.6101    0.5945      2670\n",
      "       농구_배구     0.6928    0.7969    0.7412      2708\n",
      "         러시아     0.0325    0.9168    0.0627      2487\n",
      "          무역     0.0000    0.0000    0.0000      2390\n",
      "       미국_북미     0.0000    0.0000    0.0000      1789\n",
      "         미디어     0.4938    0.0999    0.1661       801\n",
      "       미술_건축     0.5904    0.2055    0.3048       842\n",
      "         반도체     0.0000    0.0000    0.0000      1997\n",
      "       방송_연예     0.7114    0.6856    0.6983      4729\n",
      "         부동산     0.0000    0.0000    0.0000      3636\n",
      "          북한     0.7328    0.6363    0.6811      2422\n",
      "       사건_사고     0.7512    0.7693    0.7601      9123\n",
      "       산업_기업     0.0000    0.0000    0.0000      4568\n",
      "          생활     0.0000    0.0000    0.0000       160\n",
      "      서비스_쇼핑     0.0000    0.0000    0.0000      2656\n",
      "          선거     0.6615    0.6368    0.6489      8945\n",
      "         아시아     0.0000    0.0000    0.0000       716\n",
      "          여성     0.5821    0.1716    0.2650      1364\n",
      "   올림픽_아시안게임     0.7228    0.4720    0.5711      2646\n",
      "          외교     0.4992    0.5335    0.5158      2343\n",
      "          외환     0.0000    0.0000    0.0000      1489\n",
      "       요리_여행     0.5518    0.2560    0.3498       832\n",
      "       유럽_EU     0.0000    0.0000    0.0000      1794\n",
      "          유통     0.0000    0.0000    0.0000      6871\n",
      "          음악     0.6124    0.3593    0.4529       796\n",
      "       의료_건강     0.7327    0.6579    0.6933      3154\n",
      "          일본     0.0000    0.0000    0.0000       952\n",
      "         자동차     0.0000    0.0000    0.0000      4395\n",
      "          자원     0.0000    0.0000    0.0000      1940\n",
      "         장애인     0.6290    0.2838    0.3912       687\n",
      "       전시_공연     0.5358    0.6981    0.6063      5468\n",
      "          종교     0.6845    0.6364    0.6596       341\n",
      "          중국     0.0000    0.0000    0.0000      2250\n",
      "         중남미     0.0000    0.0000    0.0000       349\n",
      "     중동_아프리카     0.0000    0.0000    0.0000       202\n",
      "       증권_증시     0.0000    0.0000    0.0000      4850\n",
      "         청와대     0.5257    0.4445    0.4817      4940\n",
      "          출판     0.2066    0.1158    0.1484       380\n",
      "       취업_창업     0.0000    0.0000    0.0000     12875\n",
      "      학술_문화재     0.5935    0.4867    0.5348       600\n",
      "       행정_자치     0.4561    0.1179    0.1874      2425\n",
      "          환경     0.7528    0.3681    0.4945       728\n",
      "\n",
      "    accuracy                         0.3406    142463\n",
      "   macro avg     0.3385    0.2879    0.2892    142463\n",
      "weighted avg     0.3444    0.3406    0.3281    142463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def predict(model, tokenizer, test_dataloader, con, small_id2label):\n",
    "    model.eval()  # 평가 모드\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    texts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "            text_inputs = [str(text) for text in batch[0]]  # 입력 텍스트\n",
    "            encoded_inputs = tokenizer(text_inputs, padding=True, truncation=True, max_length=con.max_seq_len, return_tensors=\"pt\")\n",
    "            encoded_inputs = {k: v.to(con.device) for k, v in encoded_inputs.items()}\n",
    "            \n",
    "            outputs = model(**encoded_inputs)\n",
    "            logits = outputs.logits  # 예측값\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(batch[1].cpu().numpy())  # 실제 정답\n",
    "            texts.extend(batch[0])  # 원본 텍스트 저장\n",
    "\n",
    "    # 라벨 ID → 라벨명 변환\n",
    "    pred_labels = [small_id2label[p] for p in predictions]\n",
    "    true_labels = [small_id2label[t] for t in true_labels]\n",
    "\n",
    "    # 결과 데이터프레임 생성\n",
    "    df_results = pd.DataFrame({\"Text\": texts, \"True Label\": true_labels, \"Predicted Label\": pred_labels})\n",
    "\n",
    "    # 버깅: 샘플 5개 확인 (랜덤)\n",
    "    sample_indices = random.sample(range(len(df_results)), 5)\n",
    "    print(\"\\n🔍 샘플 데이터 정렬 검증\")\n",
    "    for idx in sample_indices:\n",
    "        print(f\"\\n📝 Text: {df_results.iloc[idx]['Text']}\")\n",
    "        print(f\"True Label: {df_results.iloc[idx]['True Label']}\")\n",
    "        print(f\"Predicted Label: {df_results.iloc[idx]['Predicted Label']}\")\n",
    "\n",
    "    # 성능 평가 지표 출력\n",
    "    print(\"\\n[Classification Report]\\n\")\n",
    "    print(classification_report(true_labels, pred_labels, digits=4))\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# 모델과 토크나이저 불러오기\n",
    "saved_model_path = \"/home/lhch9550/공모전/KPF-BERT-CLS/saved_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(saved_model_path).to(_config.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
    "\n",
    "# 추론 실행\n",
    "df_results = predict(model, tokenizer, test_dataloader, _config, small_id2label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
