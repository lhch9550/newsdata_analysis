{"cells":[{"cell_type":"markdown","id":"461376c8","metadata":{"id":"461376c8"},"source":["# Kpf-Bert를 이용한 뉴스기사 3줄요약 서비스  \n","전체기사에서 중요한 순서대로 상위 3개의 문장을 추출해서 제시하는 기사 요약 서비스이다.  \n","  \n","pytorch-lightning을 이용하여 전체프로세서를 작성하였다.  \n","  \n","BERT를 이용한 SUMMARY 관련 논문 및 nlpyang의 PreSumm 소스를 참조하였다."]},{"cell_type":"code","execution_count":1,"id":"5521b37c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35375,"status":"ok","timestamp":1735036347060,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"5521b37c","outputId":"50685619-bbb0-46c2-af28-4c97113dc2a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  _torch_pytree._register_pytree_node(\n","/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  _torch_pytree._register_pytree_node(\n","/home/lhch9550/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  warnings.warn(\n","Seed set to 42\n"]}],"source":["import math\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torch.optim as optim\n","\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","\n","from torch.nn.init import xavier_uniform_\n","\n","import pytorch_lightning as pl\n","from torchmetrics.functional import accuracy\n","#from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import TensorBoardLogger\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, multilabel_confusion_matrix\n","\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","\n","import kss\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","RANDOM_SEED = 42\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","rcParams['figure.figsize'] = 12, 8\n","\n","pl.seed_everything(RANDOM_SEED)\n","\n","# GPU 사용 설정\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"  # Set the GPU to use"]},{"cell_type":"code","execution_count":2,"id":"2491afee","metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1735036347060,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"2491afee"},"outputs":[],"source":["MAX_TOKEN_COUNT = 512\n","N_EPOCHS = 1\n","BATCH_SIZE = 8"]},{"cell_type":"markdown","id":"d0d05e21","metadata":{"id":"d0d05e21"},"source":["# data\n","대신 AI - HUB 에서 한국어 요약 데이터셋을 공개하여 이를 활용하였다."]},{"cell_type":"code","execution_count":3,"id":"fZQEHWVK9yst","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32157,"status":"ok","timestamp":1735036398427,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"fZQEHWVK9yst","outputId":"7b7422e1-f59d-4e4e-d351-3331f86f6d84"},"outputs":[{"name":"stdout","output_type":"stream","text":["JSON 파일이 올바르게 로드되었습니다.\n"]}],"source":["import json\n","\n","DATA_TRAIN_PATH = '/home/lhch9550/공모전/train_original.json'\n","\n","# JSON 파일 로드 및 확인\n","try:\n","    with open(DATA_TRAIN_PATH, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","    print(\"JSON 파일이 올바르게 로드되었습니다.\")\n","except json.JSONDecodeError as e:\n","    print(\"JSON 파일에 문제가 있습니다:\", e)"]},{"cell_type":"code","execution_count":6,"id":"bd033c18","metadata":{},"outputs":[],"source":["def preprocess_data(data):\n","    outs = []\n","    for doc in data['documents']:\n","        line = []\n","        line.append(doc['media_name'])\n","        line.append(doc['id'])\n","        para = []\n","        for sent in doc['text']:\n","            for s in sent:\n","                para.append(s['sentence'])\n","        line.append(para)\n","        line.append(doc['abstractive'][0])\n","        line.append(doc['extractive'])\n","        a = doc['extractive']\n","        if a[0] == None or a[1] == None or a[2] == None:\n","            continue\n","        outs.append(line)\n","\n","    outs_df = pd.DataFrame(outs)\n","    outs_df.columns = ['media', 'id', 'article_original', 'abstractive', 'extractive']\n","    return outs_df"]},{"cell_type":"code","execution_count":7,"id":"-9FEm7BO96Gl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29064,"status":"ok","timestamp":1735036429004,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"-9FEm7BO96Gl","outputId":"7d5b149f-e8e0-46e9-92d9-16d82b8325f2"},"outputs":[{"data":{"text/plain":["243983"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_json(DATA_TRAIN_PATH)\n","df = df.dropna()\n","len(df)"]},{"cell_type":"code","execution_count":8,"id":"dd6b33a6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2975,"status":"ok","timestamp":1735036431978,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"dd6b33a6","outputId":"0d630944-d3bb-4378-8b54-a312d91a8e4e"},"outputs":[{"data":{"text/plain":["30122"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["DATA_TEST_PATH = '/home/lhch9550/공모전/valid_original.json'\n","test_df = pd.read_json(DATA_TEST_PATH)\n","test_df = test_df.dropna()\n","len(test_df)"]},{"cell_type":"code","execution_count":9,"id":"eef7da04","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1735036497320,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"eef7da04","outputId":"f3377334-a55e-4df7-fc8f-7a708ffe29a0"},"outputs":[{"data":{"text/plain":["((219584, 3), (24399, 3), (30122, 3))"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_df, val_df = train_test_split(df, test_size=0.1)\n","train_df = train_df.reset_index(drop=True)\n","val_df = val_df.reset_index(drop=True)\n","train_df.shape, val_df.shape, test_df.shape"]},{"cell_type":"code","execution_count":12,"id":"39ff5b7b","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>media</th>\n","      <th>id</th>\n","      <th>article_original</th>\n","      <th>abstractive</th>\n","      <th>extractive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>매일경제</td>\n","      <td>354255482</td>\n","      <td>[채권시장에서 20년 만기 국고채 금리가 10년 만기 금리 아래로 떨어졌다., 4개...</td>\n","      <td>채권시장에서 20년물 금리가 10년물보다 낮은 '장기.초장기 채권금리간 역전' 현상...</td>\n","      <td>[6, 2, 12]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  media         id                                   article_original  \\\n","0  매일경제  354255482  [채권시장에서 20년 만기 국고채 금리가 10년 만기 금리 아래로 떨어졌다., 4개...   \n","\n","                                         abstractive  extractive  \n","0  채권시장에서 20년물 금리가 10년물보다 낮은 '장기.초장기 채권금리간 역전' 현상...  [6, 2, 12]  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_df = preprocess_data(train_df)\n","train_df.head(1)"]},{"cell_type":"code","execution_count":13,"id":"6b97e801","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["===== 본    문 =====\n","0 : 이용섭 시장, 유엔인권최고대표사무소 길모어 부대표 면담서 제안\n","1 : 오치남 기자\n","2 : 광주시·유엔, 2020년 세계인권도시포럼 공동 개최 추진\n","3 : 이용섭 시장, 유엔인권최고대표사무소 길모어 부대표 면담서 제안\n","4 : 亞국가 국제인권교육 진행…유엔과 인권증진 협력 강화도\n","5 : 이용섭 광주광역시장이 17일(현지시간) 오전 스위스 제네바 유엔인권최고대표사무소에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석, ‘인권도시 광주, 그리고 지구적 협력’을 주제로 개회연설을 하고 있다.\n","6 : /광주시 제공\n","7 : 세계인권도시로 자리잡은 광주광역시가 유엔과 2020세계인권도시포럼 공동개최를 추진하기로 했다.\n","8 : 또 유엔과 인권증진 협력을 강화하고 아시아 국가를 대상으로 국제인권교육도 진행하기로 했다.\n","9 : 이용섭 광주시장은 17일(현지시간) 스위스 제네바에서 유엔인권최고대표사무소(UN OHCHR) 케이트 길모어 부대표와 면담을 갖고 5·18민주화운동 40주년에 맞춰 유엔인권최고대표부와 내년 5월 세계인권도시포럼 공동개최를 추진키로 했다.\n","10 : 이 시장은 이와 관련한 내용을 길모어 부대표에 전달하고 미첼 바첼렛 대표(전 칠레 대통령)를 포럼에 공식 초청했다.\n","11 : 이에 대해 길모어 부대표는 “인권의 가치와 비전을 함께 공유하고 있는 유엔과 광주가 성공적인 협업모델을 만들 수 있도록 포럼 공동개최에 대해 논의를 진행하겠다”고 말했다.\n","12 : 이와 함께 광주시는 2020년부터 진행하는 국제인권교육에 유엔의 교육콘텐츠와 전문강사, 노하우도 공유하기로 했다.\n","13 : 국제인권교육은 아시아 국가들의 인권정책 전문성 강화와 국민들의 인권증진을 위해 광주시와 코이카(KOICA)가 공동으로 실시하는 것으로, 유엔은 한국사무소를 통해 광주시와 구체적인 협력 내용을 협의하기로 했다.\n","14 : 이용섭 광주광역시장이 17일(현지시간) 오전 스위스 제네바 유엔인권최고대표사무소에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석한 후 케이트 길모어 유엔인권최고대표사무소 부대표와 면담하고 있다.\n","15 : /광주시 제공\n","16 : 이 시장은 이날 제네바에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석, “인권도시가 도시운영의 중요한 지침이 돼야 한다”며 두 가지의 실천과제를 제시했다.\n","17 : 이 시장은 영어로 진행된 개회연설을 통해 “인권도시의 궁극적 목적은 모두가 행복하게 사는 인권공동체의 실현이다”며 “지금처럼 시민의 자율성과 자치가 강조되는 시대에서, 인권도시는 더욱 중요한 도시발전 비전으로 자리 잡아야 한다”고 강조했다.\n","18 : 이를 위한 실천과제로 “지역차원의 인권보호체제에 시민사회와 기업 등 지역의 다양한 이해관계자들이 참여해 공동의 실천과 협력을 해 나가야 한다”고 말했다.\n","19 : 이 시장은 ‘광주형 일자리’를 소개하면서 “사회대타협을 통해 보다 많은 노동자들이 양질의 일자리를 갖는 것 또한 인권증진의 일환이다”며 “광주는 경제·사회적 약자에 대한 포용을 통해 인권공동체를 추구해 가고 있다”고 밝혔다.\n","20 : 이어 “유엔을 포함한 국제기구, 국가, 지방정부가 인권을 중심으로 강한 파트너십을 구축해야 한다”며 “오는 9월 광주에서 열리는 2019세계인권도시포럼에서 우리가 다시 만나 인권도시의 지속적인 성장과 지구적 차원의 인권연대 강화를 위한 혁신적인 방안을 구체적으로 논의할 수 있기를 바란다”고 말했다.\n","21 : 한편, 이 시장은 사회통합·참여민주주의·인권에 관한 세계지방정부연합 위원회(UCLG-CSIPDHR) 공동의장 자격으로 회의에 초청됐으며, 로마, 바르셀로나, 멕시코시티, 비엔나, 제네바, 파리, 애틀란타, 카트만두, 울란바토르 등 20여 개 인권도시에서 100여 명의 관계자가 참석했다.\n","22 : /오치남 기자 ocn@namdonews.com\n","23 : 이용섭 광주광역시장이 17일(현지시간) 오전 스위스 제네바 유엔인권최고대표사무소에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석, ‘인권도시 광주, 그리고 지구적 협력’을 주제로 개회연설을 하고 있다.\n","24 : /광주시 제공\n","25 : 오치남 기자 ocn@namdonews.com\n","===== 요약정답 =====\n","[9, 11, 12]\n","===== 추출본문 =====\n","1 : 이용섭 광주시장은 17일(현지시간) 스위스 제네바에서 유엔인권최고대표사무소(UN OHCHR) 케이트 길모어 부대표와 면담을 갖고 5·18민주화운동 40주년에 맞춰 유엔인권최고대표부와 내년 5월 세계인권도시포럼 공동개최를 추진키로 했다.\n","2 : 이에 대해 길모어 부대표는 “인권의 가치와 비전을 함께 공유하고 있는 유엔과 광주가 성공적인 협업모델을 만들 수 있도록 포럼 공동개최에 대해 논의를 진행하겠다”고 말했다.\n","3 : 이와 함께 광주시는 2020년부터 진행하는 국제인권교육에 유엔의 교육콘텐츠와 전문강사, 노하우도 공유하기로 했다.\n","===== 생성본문 =====\n","17일 광주시는 스위스 제네바에서 5·18민주화운동 40주년에 맞춰 인권의 가치와 비전을 함께 공유하고 있는 유엔과 광주가 성공적인 협업모델을 만들 수 있도록 유엔인권최고대표부와 내년 5월 세계인권도시포럼 공동개최를 추진키로 했다.\n"]}],"source":["i = 8\n","print('===== 본    문 =====')\n","for idx, str in enumerate(train_df['article_original'][i]):\n","    print(idx,':',str)\n","print('===== 요약정답 =====')\n","print(train_df['extractive'][i])\n","print('===== 추출본문 =====')\n","print('1 :', train_df['article_original'][i][train_df['extractive'][i][0]])\n","print('2 :', train_df['article_original'][i][train_df['extractive'][i][1]])\n","print('3 :', train_df['article_original'][i][train_df['extractive'][i][2]])\n","print('===== 생성본문 =====')\n","print(train_df['abstractive'][i])"]},{"cell_type":"code","execution_count":14,"id":"36680564","metadata":{"executionInfo":{"elapsed":1032,"status":"ok","timestamp":1735036503255,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"36680564"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>media</th>\n","      <th>id</th>\n","      <th>article_original</th>\n","      <th>abstractive</th>\n","      <th>extractive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>한국경제</td>\n","      <td>340626877</td>\n","      <td>[[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...</td>\n","      <td>8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...</td>\n","      <td>[0, 1, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  media         id                                   article_original  \\\n","0  한국경제  340626877  [[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...   \n","\n","                                         abstractive extractive  \n","0  8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...  [0, 1, 3]  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["test_df = preprocess_data(test_df)\n","test_df.head(1)"]},{"cell_type":"code","execution_count":15,"id":"3481c13a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1735036503776,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"3481c13a","outputId":"05201143-6f17-45e5-e47c-3118b005bd29"},"outputs":[{"data":{"text/plain":["((219578, 5), (30121, 5), (24399, 3))"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape, test_df.shape, val_df.shape"]},{"cell_type":"markdown","id":"71610362","metadata":{"id":"71610362"},"source":["# preprocess  \n","  \n","AI-HUB 문서요약 데이터셋 기준 전처리  \n","-> 기존 Bflysoft-뉴스기사 데이터셋에 맞춰 변환  \n","위 데이터를 구하지 못해서 다른 데이터를 변환한 것이다.  \n","사실 거칠 필요가 없는 과정이 되어버렸다."]},{"cell_type":"code","execution_count":16,"id":"050ee210","metadata":{"executionInfo":{"elapsed":528,"status":"ok","timestamp":1735036507583,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"050ee210"},"outputs":[],"source":["def preprocess_data(data):\n","    outs = []\n","    for doc in data['documents']:\n","        line = []\n","        line.append(doc['media_name'])\n","        line.append(doc['id'])\n","        para = []\n","        for sent in doc['text']:\n","            for s in sent:\n","                para.append(s['sentence'])\n","        line.append(para)\n","        line.append(doc['abstractive'][0])\n","        line.append(doc['extractive'])\n","        a = doc['extractive']\n","        if a[0] == None or a[1] == None or a[2] == None:\n","            continue\n","        outs.append(line)\n","\n","    outs_df = pd.DataFrame(outs)\n","    outs_df.columns = ['media', 'id', 'article_original', 'abstractive', 'extractive']\n","    return outs_df"]},{"cell_type":"code","execution_count":17,"id":"dff9fea8","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>media</th>\n","      <th>id</th>\n","      <th>article_original</th>\n","      <th>abstractive</th>\n","      <th>extractive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>매일경제</td>\n","      <td>354255482</td>\n","      <td>[채권시장에서 20년 만기 국고채 금리가 10년 만기 금리 아래로 떨어졌다., 4개...</td>\n","      <td>채권시장에서 20년물 금리가 10년물보다 낮은 '장기.초장기 채권금리간 역전' 현상...</td>\n","      <td>[6, 2, 12]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>매일경제</td>\n","      <td>351711827</td>\n","      <td>[중소 증권사 오너들이 경영 보폭을 넓히고 있다., 캐피털 진출과 광고 확대, 대학...</td>\n","      <td>7일 금융투자업계에 따르면 , 금융위원회는 리딩투자증권의 캐피탈 출자 승인 안건을 ...</td>\n","      <td>[2, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>제주일보</td>\n","      <td>356271062</td>\n","      <td>[제주도, 9월 30일까지...수급조절 유통처리대책 마련 위해 신고 당부, 제주지역...</td>\n","      <td>13일 제주특별자치도는 다음달 30일까지 채소류 재배면적 신고를 접수한다고 밝혔는데...</td>\n","      <td>[2, 3, 7]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>아주경제</td>\n","      <td>358585637</td>\n","      <td>[서울시가 강남북 균형발전을 위해 2024년까지 인재개발원, 서울연구원, 서울주택도...</td>\n","      <td>서울시가 강남북 균형발전을 위해 2024년까지 3개의 공공기관을 강북으로 이전하겠다...</td>\n","      <td>[0, 1, 7]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>제민일보</td>\n","      <td>337240119</td>\n","      <td>[제주도감사위, 12일 제주시·서귀포시교육지원 감사 결과 발표, 제주시교육지원청이 ...</td>\n","      <td>제주도감사위원회는 종합감사를 실시하여 제주시교육지원청이 성과 상여금을 잘못 지급하고...</td>\n","      <td>[1, 2, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>219573</th>\n","      <td>전북도민일보</td>\n","      <td>342904723</td>\n","      <td>[전북도는 24일 고사동 객리단길 내 전주영화도서관&amp;카페에서 '제1회 도란도란 토크...</td>\n","      <td>전북도는, 도지사 공약사업 실천 및 청년들의 아이디어를 도정에 접목시키기 위해, 2...</td>\n","      <td>[0, 1, 4]</td>\n","    </tr>\n","    <tr>\n","      <th>219574</th>\n","      <td>전라일보</td>\n","      <td>353473510</td>\n","      <td>[홍민희 기자l minihong2503@naver.com, 우수한 연구원들의 정주여...</td>\n","      <td>전북테크노파크가 오는 24일까지 R&amp;D기관 우수연구원 유치를 위한 주거비 지원사업을...</td>\n","      <td>[2, 3, 4]</td>\n","    </tr>\n","    <tr>\n","      <th>219575</th>\n","      <td>중부매일</td>\n","      <td>339576576</td>\n","      <td>[불법행위 '택시기사 삼진아웃제' 6월 시행[중부매일 이민우 기자] 지난달 충북지역...</td>\n","      <td>청주시는 오는 6월부터 승차거부, 부당요금 징수 등 불법행위를 최근 2년 이내 3회...</td>\n","      <td>[2, 4, 7]</td>\n","    </tr>\n","    <tr>\n","      <th>219576</th>\n","      <td>충청일보</td>\n","      <td>332010887</td>\n","      <td>[도교육청, 오는 3월 예정, 내달 15일까지 단원 모집, [충청일보 이정규기자] ...</td>\n","      <td>충북예술교육을 이끌어 갈 충북청소년국악관현악단이 오는 3월 창단을 목표로 도내 초,...</td>\n","      <td>[3, 4, 10]</td>\n","    </tr>\n","    <tr>\n","      <th>219577</th>\n","      <td>전북일보</td>\n","      <td>344515561</td>\n","      <td>[기고, 사례자는 2000년생으로서 2019년도 병역판정검사대상자입니다., 병역판정...</td>\n","      <td>6월에 병역판정을 받고자 하는 사례자는 전북도내 광주전남지방병무청, 실거주지에서도 ...</td>\n","      <td>[3, 6, 8]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>219578 rows × 5 columns</p>\n","</div>"],"text/plain":["         media         id                                   article_original  \\\n","0         매일경제  354255482  [채권시장에서 20년 만기 국고채 금리가 10년 만기 금리 아래로 떨어졌다., 4개...   \n","1         매일경제  351711827  [중소 증권사 오너들이 경영 보폭을 넓히고 있다., 캐피털 진출과 광고 확대, 대학...   \n","2         제주일보  356271062  [제주도, 9월 30일까지...수급조절 유통처리대책 마련 위해 신고 당부, 제주지역...   \n","3         아주경제  358585637  [서울시가 강남북 균형발전을 위해 2024년까지 인재개발원, 서울연구원, 서울주택도...   \n","4         제민일보  337240119  [제주도감사위, 12일 제주시·서귀포시교육지원 감사 결과 발표, 제주시교육지원청이 ...   \n","...        ...        ...                                                ...   \n","219573  전북도민일보  342904723  [전북도는 24일 고사동 객리단길 내 전주영화도서관&카페에서 '제1회 도란도란 토크...   \n","219574    전라일보  353473510  [홍민희 기자l minihong2503@naver.com, 우수한 연구원들의 정주여...   \n","219575    중부매일  339576576  [불법행위 '택시기사 삼진아웃제' 6월 시행[중부매일 이민우 기자] 지난달 충북지역...   \n","219576    충청일보  332010887  [도교육청, 오는 3월 예정, 내달 15일까지 단원 모집, [충청일보 이정규기자] ...   \n","219577    전북일보  344515561  [기고, 사례자는 2000년생으로서 2019년도 병역판정검사대상자입니다., 병역판정...   \n","\n","                                              abstractive  extractive  \n","0       채권시장에서 20년물 금리가 10년물보다 낮은 '장기.초장기 채권금리간 역전' 현상...  [6, 2, 12]  \n","1       7일 금융투자업계에 따르면 , 금융위원회는 리딩투자증권의 캐피탈 출자 승인 안건을 ...   [2, 1, 0]  \n","2       13일 제주특별자치도는 다음달 30일까지 채소류 재배면적 신고를 접수한다고 밝혔는데...   [2, 3, 7]  \n","3       서울시가 강남북 균형발전을 위해 2024년까지 3개의 공공기관을 강북으로 이전하겠다...   [0, 1, 7]  \n","4       제주도감사위원회는 종합감사를 실시하여 제주시교육지원청이 성과 상여금을 잘못 지급하고...   [1, 2, 3]  \n","...                                                   ...         ...  \n","219573  전북도는, 도지사 공약사업 실천 및 청년들의 아이디어를 도정에 접목시키기 위해, 2...   [0, 1, 4]  \n","219574  전북테크노파크가 오는 24일까지 R&D기관 우수연구원 유치를 위한 주거비 지원사업을...   [2, 3, 4]  \n","219575  청주시는 오는 6월부터 승차거부, 부당요금 징수 등 불법행위를 최근 2년 이내 3회...   [2, 4, 7]  \n","219576  충북예술교육을 이끌어 갈 충북청소년국악관현악단이 오는 3월 창단을 목표로 도내 초,...  [3, 4, 10]  \n","219577  6월에 병역판정을 받고자 하는 사례자는 전북도내 광주전남지방병무청, 실거주지에서도 ...   [3, 6, 8]  \n","\n","[219578 rows x 5 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":18,"id":"b107ac5a","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>media</th>\n","      <th>id</th>\n","      <th>article_original</th>\n","      <th>abstractive</th>\n","      <th>extractive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>한국경제</td>\n","      <td>340626877</td>\n","      <td>[[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...</td>\n","      <td>8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...</td>\n","      <td>[0, 1, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>한국경제</td>\n","      <td>340626896</td>\n","      <td>[] 당 지도부 퇴진을 놓고 바른미래당 내홍이 격화되고 있다., 바른미래당이 8일 ...</td>\n","      <td>8일 바른미래당 최고의원 회의에 하태경 의원 등 5명의 최고의원이 지도부 퇴진을 요...</td>\n","      <td>[2, 1, 6]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>한국경제</td>\n","      <td>340626904</td>\n","      <td>[[ 홍윤정 기자 ] 8일 서울 올림픽공원 K아트홀., 지난 3일 한국이 세계 최초...</td>\n","      <td>지난 3일 한국이 세계 첫 5세대 이동통신 서비스를 보편화한 것을 축하하는 '코리안...</td>\n","      <td>[1, 5, 8]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>한국경제</td>\n","      <td>340627450</td>\n","      <td>[] 박원순 서울시장(사진)이 8일 고층 재개발·재건축 관련 요구에 작심한 듯 쓴소...</td>\n","      <td>박원순 서울시장은 8일 서울시청에서 열린 '골목길 재생 시민 정책 대화'에 참석하여...</td>\n","      <td>[0, 1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>한국경제</td>\n","      <td>340627465</td>\n","      <td>[[ 임근호 기자 ] \"SK(주)와 미국 알파벳(구글 지주회사)의 간결한 지배구조를...</td>\n","      <td>주주가치 포커스를 운용하는 KB자산운용이  SK와 알파벳(구글 지주회사)의 모범적 ...</td>\n","      <td>[1, 3, 4]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>30116</th>\n","      <td>헤럴드경제</td>\n","      <td>350851474</td>\n","      <td>[영주시는 이억만리에서 건너온 계절근로자들의 향수를 달래고 안정된 한국생활 적응을 ...</td>\n","      <td>영주시는 외국인 근로자들의 향수를 달래고, 안정적인 한국생활 적응을 지원하기 위해 ...</td>\n","      <td>[0, 1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>30117</th>\n","      <td>헤럴드경제</td>\n","      <td>350851925</td>\n","      <td>[여름 방학을 맞아 전국의 국립과학관에서 달 탐사 50주년과 국제천문연맹(IAU) ...</td>\n","      <td>달 탐사 50주년과 국제천문연맹(IAU)설립 100주년 기념하는 특별전시가 전국의 ...</td>\n","      <td>[0, 1, 12]</td>\n","    </tr>\n","    <tr>\n","      <th>30118</th>\n","      <td>헤럴드경제</td>\n","      <td>350854748</td>\n","      <td>[영주문경예천 당원협의회 시국강연 및 당원교육에 참석차 영주를 방문한 황교안(오른쪽...</td>\n","      <td>황교안 대표는 지난 29일 자유한국당 대표로 경북 영주문경예청 당원협의회 당원교육에...</td>\n","      <td>[2, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>30119</th>\n","      <td>헤럴드경제</td>\n","      <td>350857648</td>\n","      <td>[경북예천군은 장기적인 국내 경기침체가 지속됨에 따라 사회적경제 기업 육성 등을 통...</td>\n","      <td>경북예천군은 사회적경제 기업 육성 등을 통한 일자리 창출에 행정동력을 집중한 결과 ...</td>\n","      <td>[0, 3, 4]</td>\n","    </tr>\n","    <tr>\n","      <th>30120</th>\n","      <td>헤럴드경제</td>\n","      <td>350861693</td>\n","      <td>[3기 신도시 등 '수도권 30만 가구 공급' 계획이 7월 의왕 청계2, 성남 신촌...</td>\n","      <td>국토교통부에 따르면 의왕 청계2, 성남 신총 등 4개 지구가 중앙도시계획위 심의를 ...</td>\n","      <td>[0, 1, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>30121 rows × 5 columns</p>\n","</div>"],"text/plain":["       media         id                                   article_original  \\\n","0       한국경제  340626877  [[ 박재원 기자 ] '대한민국 5G 홍보대사'를 자처한 문재인 대통령은 \"넓고, ...   \n","1       한국경제  340626896  [] 당 지도부 퇴진을 놓고 바른미래당 내홍이 격화되고 있다., 바른미래당이 8일 ...   \n","2       한국경제  340626904  [[ 홍윤정 기자 ] 8일 서울 올림픽공원 K아트홀., 지난 3일 한국이 세계 최초...   \n","3       한국경제  340627450  [] 박원순 서울시장(사진)이 8일 고층 재개발·재건축 관련 요구에 작심한 듯 쓴소...   \n","4       한국경제  340627465  [[ 임근호 기자 ] \"SK(주)와 미국 알파벳(구글 지주회사)의 간결한 지배구조를...   \n","...      ...        ...                                                ...   \n","30116  헤럴드경제  350851474  [영주시는 이억만리에서 건너온 계절근로자들의 향수를 달래고 안정된 한국생활 적응을 ...   \n","30117  헤럴드경제  350851925  [여름 방학을 맞아 전국의 국립과학관에서 달 탐사 50주년과 국제천문연맹(IAU) ...   \n","30118  헤럴드경제  350854748  [영주문경예천 당원협의회 시국강연 및 당원교육에 참석차 영주를 방문한 황교안(오른쪽...   \n","30119  헤럴드경제  350857648  [경북예천군은 장기적인 국내 경기침체가 지속됨에 따라 사회적경제 기업 육성 등을 통...   \n","30120  헤럴드경제  350861693  [3기 신도시 등 '수도권 30만 가구 공급' 계획이 7월 의왕 청계2, 성남 신촌...   \n","\n","                                             abstractive  extractive  \n","0      8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 혁...   [0, 1, 3]  \n","1      8일 바른미래당 최고의원 회의에 하태경 의원 등 5명의 최고의원이 지도부 퇴진을 요...   [2, 1, 6]  \n","2      지난 3일 한국이 세계 첫 5세대 이동통신 서비스를 보편화한 것을 축하하는 '코리안...   [1, 5, 8]  \n","3      박원순 서울시장은 8일 서울시청에서 열린 '골목길 재생 시민 정책 대화'에 참석하여...   [0, 1, 2]  \n","4      주주가치 포커스를 운용하는 KB자산운용이  SK와 알파벳(구글 지주회사)의 모범적 ...   [1, 3, 4]  \n","...                                                  ...         ...  \n","30116  영주시는 외국인 근로자들의 향수를 달래고, 안정적인 한국생활 적응을 지원하기 위해 ...   [0, 1, 2]  \n","30117  달 탐사 50주년과 국제천문연맹(IAU)설립 100주년 기념하는 특별전시가 전국의 ...  [0, 1, 12]  \n","30118  황교안 대표는 지난 29일 자유한국당 대표로 경북 영주문경예청 당원협의회 당원교육에...   [2, 0, 1]  \n","30119  경북예천군은 사회적경제 기업 육성 등을 통한 일자리 창출에 행정동력을 집중한 결과 ...   [0, 3, 4]  \n","30120  국토교통부에 따르면 의왕 청계2, 성남 신총 등 4개 지구가 중앙도시계획위 심의를 ...   [0, 1, 3]  \n","\n","[30121 rows x 5 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":19,"id":"40702bc0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1735036519964,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"40702bc0","outputId":"b284f15f-059a-4dd0-b771-f47144ffb144"},"outputs":[{"name":"stdout","output_type":"stream","text":["===== 본    문 =====\n","0 : 이용섭 시장, 유엔인권최고대표사무소 길모어 부대표 면담서 제안\n","1 : 오치남 기자\n","2 : 광주시·유엔, 2020년 세계인권도시포럼 공동 개최 추진\n","3 : 이용섭 시장, 유엔인권최고대표사무소 길모어 부대표 면담서 제안\n","4 : 亞국가 국제인권교육 진행…유엔과 인권증진 협력 강화도\n","5 : 이용섭 광주광역시장이 17일(현지시간) 오전 스위스 제네바 유엔인권최고대표사무소에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석, ‘인권도시 광주, 그리고 지구적 협력’을 주제로 개회연설을 하고 있다.\n","6 : /광주시 제공\n","7 : 세계인권도시로 자리잡은 광주광역시가 유엔과 2020세계인권도시포럼 공동개최를 추진하기로 했다.\n","8 : 또 유엔과 인권증진 협력을 강화하고 아시아 국가를 대상으로 국제인권교육도 진행하기로 했다.\n","9 : 이용섭 광주시장은 17일(현지시간) 스위스 제네바에서 유엔인권최고대표사무소(UN OHCHR) 케이트 길모어 부대표와 면담을 갖고 5·18민주화운동 40주년에 맞춰 유엔인권최고대표부와 내년 5월 세계인권도시포럼 공동개최를 추진키로 했다.\n","10 : 이 시장은 이와 관련한 내용을 길모어 부대표에 전달하고 미첼 바첼렛 대표(전 칠레 대통령)를 포럼에 공식 초청했다.\n","11 : 이에 대해 길모어 부대표는 “인권의 가치와 비전을 함께 공유하고 있는 유엔과 광주가 성공적인 협업모델을 만들 수 있도록 포럼 공동개최에 대해 논의를 진행하겠다”고 말했다.\n","12 : 이와 함께 광주시는 2020년부터 진행하는 국제인권교육에 유엔의 교육콘텐츠와 전문강사, 노하우도 공유하기로 했다.\n","13 : 국제인권교육은 아시아 국가들의 인권정책 전문성 강화와 국민들의 인권증진을 위해 광주시와 코이카(KOICA)가 공동으로 실시하는 것으로, 유엔은 한국사무소를 통해 광주시와 구체적인 협력 내용을 협의하기로 했다.\n","14 : 이용섭 광주광역시장이 17일(현지시간) 오전 스위스 제네바 유엔인권최고대표사무소에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석한 후 케이트 길모어 유엔인권최고대표사무소 부대표와 면담하고 있다.\n","15 : /광주시 제공\n","16 : 이 시장은 이날 제네바에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석, “인권도시가 도시운영의 중요한 지침이 돼야 한다”며 두 가지의 실천과제를 제시했다.\n","17 : 이 시장은 영어로 진행된 개회연설을 통해 “인권도시의 궁극적 목적은 모두가 행복하게 사는 인권공동체의 실현이다”며 “지금처럼 시민의 자율성과 자치가 강조되는 시대에서, 인권도시는 더욱 중요한 도시발전 비전으로 자리 잡아야 한다”고 강조했다.\n","18 : 이를 위한 실천과제로 “지역차원의 인권보호체제에 시민사회와 기업 등 지역의 다양한 이해관계자들이 참여해 공동의 실천과 협력을 해 나가야 한다”고 말했다.\n","19 : 이 시장은 ‘광주형 일자리’를 소개하면서 “사회대타협을 통해 보다 많은 노동자들이 양질의 일자리를 갖는 것 또한 인권증진의 일환이다”며 “광주는 경제·사회적 약자에 대한 포용을 통해 인권공동체를 추구해 가고 있다”고 밝혔다.\n","20 : 이어 “유엔을 포함한 국제기구, 국가, 지방정부가 인권을 중심으로 강한 파트너십을 구축해야 한다”며 “오는 9월 광주에서 열리는 2019세계인권도시포럼에서 우리가 다시 만나 인권도시의 지속적인 성장과 지구적 차원의 인권연대 강화를 위한 혁신적인 방안을 구체적으로 논의할 수 있기를 바란다”고 말했다.\n","21 : 한편, 이 시장은 사회통합·참여민주주의·인권에 관한 세계지방정부연합 위원회(UCLG-CSIPDHR) 공동의장 자격으로 회의에 초청됐으며, 로마, 바르셀로나, 멕시코시티, 비엔나, 제네바, 파리, 애틀란타, 카트만두, 울란바토르 등 20여 개 인권도시에서 100여 명의 관계자가 참석했다.\n","22 : /오치남 기자 ocn@namdonews.com\n","23 : 이용섭 광주광역시장이 17일(현지시간) 오전 스위스 제네바 유엔인권최고대표사무소에서 열린 ‘유엔·지방정부연합 인권협의회의’에 참석, ‘인권도시 광주, 그리고 지구적 협력’을 주제로 개회연설을 하고 있다.\n","24 : /광주시 제공\n","25 : 오치남 기자 ocn@namdonews.com\n","===== 요약정답 =====\n","[9, 11, 12]\n","===== 추출본문 =====\n","1 : 이용섭 광주시장은 17일(현지시간) 스위스 제네바에서 유엔인권최고대표사무소(UN OHCHR) 케이트 길모어 부대표와 면담을 갖고 5·18민주화운동 40주년에 맞춰 유엔인권최고대표부와 내년 5월 세계인권도시포럼 공동개최를 추진키로 했다.\n","2 : 이에 대해 길모어 부대표는 “인권의 가치와 비전을 함께 공유하고 있는 유엔과 광주가 성공적인 협업모델을 만들 수 있도록 포럼 공동개최에 대해 논의를 진행하겠다”고 말했다.\n","3 : 이와 함께 광주시는 2020년부터 진행하는 국제인권교육에 유엔의 교육콘텐츠와 전문강사, 노하우도 공유하기로 했다.\n","===== 생성본문 =====\n","17일 광주시는 스위스 제네바에서 5·18민주화운동 40주년에 맞춰 인권의 가치와 비전을 함께 공유하고 있는 유엔과 광주가 성공적인 협업모델을 만들 수 있도록 유엔인권최고대표부와 내년 5월 세계인권도시포럼 공동개최를 추진키로 했다.\n"]}],"source":["i = 8\n","print('===== 본    문 =====')\n","for idx, str in enumerate(train_df['article_original'][i]):\n","    print(idx,':',str)\n","print('===== 요약정답 =====')\n","print(train_df['extractive'][i])\n","print('===== 추출본문 =====')\n","print('1 :', train_df['article_original'][i][train_df['extractive'][i][0]])\n","print('2 :', train_df['article_original'][i][train_df['extractive'][i][1]])\n","print('3 :', train_df['article_original'][i][train_df['extractive'][i][2]])\n","print('===== 생성본문 =====')\n","print(train_df['abstractive'][i])"]},{"cell_type":"markdown","id":"66f5e23f","metadata":{"id":"66f5e23f"},"source":["# tokenizer\n","kpfBERT 토크나이저를 바로 쓴다.\n","kpfBERT 토크나이저는 형태소와 유사하게 잘 토크나이징을 하게 설계되어 있다."]},{"cell_type":"code","execution_count":20,"id":"d50aeb72","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036540873,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"d50aeb72"},"outputs":[],"source":["BERT_MODEL_NAME = \"/home/lhch9550/공모전\" # kpf-BERT 경로 입력\n","tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"]},{"cell_type":"markdown","id":"61dafc56","metadata":{"id":"61dafc56"},"source":["# dataset\n","bert에서 여러문장을 입력하기 위해 presumm 에서 제안한 형식으로 인코딩 한다.  \n","  \n","token embedding : < CLS > 문장 < SEP > 문장 < SEP > 문장 ... 문장 < SEP >  \n","interval segment : 0 , 0 , 0 , 1 , 1 , 0 , 0 , ... 1 , 1  \n","position embedding : 1 , 1 , 1 , 1 , 1 , 1 , 1 , ... 1 , 1  \n","  "]},{"cell_type":"code","execution_count":21,"id":"3eafb0f2","metadata":{"executionInfo":{"elapsed":704,"status":"ok","timestamp":1735036544075,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"3eafb0f2"},"outputs":[],"source":["class SummDataset(Dataset): # 데이터셋 presumm 방식 인코딩\n","\n","    def __init__(\n","        self,\n","        data: pd.DataFrame,\n","        tokenizer: BertTokenizer,\n","        max_token_len: int = 512\n","    ):\n","        self.tokenizer = tokenizer\n","        self.data = data\n","        self.max_token_len = max_token_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index: int):\n","        data_row = self.data.iloc[index]\n","\n","        tokenlist = []\n","        for sent in data_row.article_original:\n","            tokenlist.append(tokenizer(\n","                text = sent,\n","                add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n","\n","        src = [] # 토크나이징 된 전체 문단\n","        labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n","        segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n","        clss = []  #[CLS]토큰의 포지션값을 지정\n","\n","        odd = 0\n","        for tkns in tokenlist:\n","            if odd > 1 : odd = 0\n","            clss = clss + [len(src)]\n","            src = src + tkns['input_ids']\n","            segs = segs + [odd] * len(tkns['input_ids'])\n","            if tokenlist.index(tkns) in data_row.extractive :\n","                labels = labels + [1]\n","            else:\n","                labels = labels + [0]\n","            odd += 1\n","\n","            #truncation\n","            if len(src) == MAX_TOKEN_COUNT:\n","                break\n","            elif len(src) > MAX_TOKEN_COUNT:\n","                src = src[:self.max_token_len - 1] + [src[-1]]\n","                segs = segs[:self.max_token_len]\n","                break\n","\n","        #padding\n","        if len(src) < MAX_TOKEN_COUNT:\n","            src = src + [0]*(self.max_token_len - len(src))\n","            segs = segs + [0]*(self.max_token_len - len(segs))\n","\n","        if len(clss) < MAX_TOKEN_COUNT:\n","            clss = clss + [-1]*(self.max_token_len - len(clss))\n","        if len(labels) < MAX_TOKEN_COUNT:\n","            labels = labels + [0]*(self.max_token_len - len(labels))\n","\n","        return dict(\n","            src = torch.tensor(src),\n","            segs = torch.tensor(segs),\n","            clss = torch.tensor(clss),\n","            labels= torch.FloatTensor(labels)\n","        )"]},{"cell_type":"code","execution_count":22,"id":"a3ed02d0","metadata":{"executionInfo":{"elapsed":717,"status":"ok","timestamp":1735036546823,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"a3ed02d0"},"outputs":[],"source":["class SummDataModule(pl.LightningDataModule): # presumm 인코딩 모듈\n","\n","    def __init__(self, train_df, test_df, val_df, tokenizer, batch_size=1, max_token_len=512):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.train_df = train_df\n","        self.test_df = test_df\n","        self.val_df = val_df\n","        self.tokenizer = tokenizer\n","        self.max_token_len = max_token_len\n","\n","    def setup(self, stage=None):\n","        self.train_dataset = SummDataset(\n","            self.train_df,\n","            self.tokenizer,\n","            self.max_token_len\n","        )\n","\n","        self.test_dataset = SummDataset(\n","            self.test_df,\n","            self.tokenizer,\n","            self.max_token_len\n","        )\n","\n","        self.val_dataset = SummDataset(\n","            self.val_df,\n","            self.tokenizer,\n","            self.max_token_len\n","        )\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=20 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n","        )\n","\n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.batch_size,\n","            num_workers=20 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n","        )\n","\n","    def test_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.batch_size,\n","            num_workers=20 # windows는 0으로 고정해야 에러 안난다. num_workers=2\n","        )"]},{"cell_type":"code","execution_count":23,"id":"30e96eb8","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036548673,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"30e96eb8"},"outputs":[],"source":["data_module = SummDataModule(\n","  train_df,\n","  test_df,\n","  val_df,\n","  tokenizer,\n","  batch_size=BATCH_SIZE,\n","  max_token_len=MAX_TOKEN_COUNT\n",")"]},{"cell_type":"markdown","id":"407eb538","metadata":{"id":"407eb538"},"source":["# MODEL\n","  \n","kpfBERT를 pretrained_bert로 불러와서 후처리 레이어를 추가하여 문장추출 모델을 만든다."]},{"cell_type":"code","execution_count":13,"id":"324f65c2","metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1735036551577,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"324f65c2"},"outputs":[],"source":["class PositionalEncoding(nn.Module): # positional embedding\n","\n","    def __init__(self, dropout, dim, max_len=5000):\n","        pe = torch.zeros(max_len, dim)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n","                              -(math.log(10000.0) / dim)))\n","        pe[:, 0::2] = torch.sin(position.float() * div_term)\n","        pe[:, 1::2] = torch.cos(position.float() * div_term)\n","        pe = pe.unsqueeze(0)\n","        super(PositionalEncoding, self).__init__()\n","        self.register_buffer('pe', pe)\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.dim = dim\n","\n","    def forward(self, emb, step=None):\n","        emb = emb * math.sqrt(self.dim)\n","        if (step):\n","            emb = emb + self.pe[:, step][:, None, :]\n","\n","        else:\n","            emb = emb + self.pe[:, :emb.size(1)]\n","        emb = self.dropout(emb)\n","        return emb\n","\n","    def get_emb(self, emb):\n","        return self.pe[:, :emb.size(1)]"]},{"cell_type":"code","execution_count":14,"id":"34d7d27c","metadata":{"executionInfo":{"elapsed":762,"status":"ok","timestamp":1735036554120,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"34d7d27c"},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, d_ff, dropout):\n","        super(TransformerEncoderLayer, self).__init__()\n","\n","        self.self_attn = MultiHeadedAttention(\n","            heads, d_model, dropout=dropout)\n","        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n","        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, iter, query, inputs, mask):\n","        if (iter != 0):\n","            input_norm = self.layer_norm(inputs)\n","        else:\n","            input_norm = inputs\n","\n","        mask = mask.unsqueeze(1)\n","        context = self.self_attn(input_norm, input_norm, input_norm,\n","                                 mask=mask)\n","        out = self.dropout(context) + inputs\n","        return self.feed_forward(out)"]},{"cell_type":"code","execution_count":15,"id":"da055122","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036555844,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"da055122"},"outputs":[],"source":["class ExtTransformerEncoder(nn.Module):\n","    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.2, num_inter_layers=2):\n","        super(ExtTransformerEncoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_inter_layers = num_inter_layers\n","        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n","        self.transformer_inter = nn.ModuleList(\n","            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n","            for _ in range(num_inter_layers)])\n","        self.dropout = nn.Dropout(dropout)\n","        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n","        self.wo = nn.Linear(hidden_size, 1, bias=True)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, top_vecs, mask):\n","        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n","\n","        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n","        pos_emb = self.pos_emb.pe[:, :n_sents]\n","        x = top_vecs * mask[:, :, None].float()\n","        x = x + pos_emb\n","\n","        for i in range(self.num_inter_layers):\n","            x = self.transformer_inter[i](i, x, x, ~mask)\n","\n","        x = self.layer_norm(x)\n","        sent_scores = self.sigmoid(self.wo(x))\n","        sent_scores = sent_scores.squeeze(-1) * mask.float()\n","\n","        return sent_scores"]},{"cell_type":"code","execution_count":16,"id":"f635acc3","metadata":{"executionInfo":{"elapsed":587,"status":"ok","timestamp":1735036557806,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"f635acc3"},"outputs":[],"source":["class PositionwiseFeedForward(nn.Module):\n","    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n","\n","    Args:\n","        d_model (int): the size of input for the first-layer of the FFN.\n","        d_ff (int): the hidden layer size of the second-layer\n","            of the FNN.\n","        dropout (float): dropout probability in :math:`[0, 1)`.\n","    \"\"\"\n","\n","    def __init__(self, d_model, d_ff, dropout=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.w_1 = nn.Linear(d_model, d_ff)\n","        self.w_2 = nn.Linear(d_ff, d_model)\n","        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def gelu(self, x):\n","        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n","\n","\n","    def forward(self, x):\n","        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n","        output = self.dropout_2(self.w_2(inter))\n","        return output + x"]},{"cell_type":"code","execution_count":17,"id":"6397849c","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036561494,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"6397849c"},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    \"\"\"\n","    Multi-Head Attention module from\n","    \"Attention is All You Need\"\n","    :cite:`DBLP:journals/corr/VaswaniSPUJGKP17`.\n","\n","    Similar to standard `dot` attention but uses\n","    multiple attention distributions simulataneously\n","    to select relevant items.\n","\n","    .. mermaid::\n","\n","       graph BT\n","          A[key]\n","          B[value]\n","          C[query]\n","          O[output]\n","          subgraph Attn\n","            D[Attn 1]\n","            E[Attn 2]\n","            F[Attn N]\n","          end\n","          A --> D\n","          C --> D\n","          A --> E\n","          C --> E\n","          A --> F\n","          C --> F\n","          D --> O\n","          E --> O\n","          F --> O\n","          B --> O\n","\n","    Also includes several additional tricks.\n","\n","    Args:\n","       head_count (int): number of parallel heads\n","       model_dim (int): the dimension of keys/values/queries,\n","           must be divisible by head_count\n","       dropout (float): dropout parameter\n","    \"\"\"\n","\n","    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n","        assert model_dim % head_count == 0\n","        self.dim_per_head = model_dim // head_count\n","        self.model_dim = model_dim\n","\n","        super(MultiHeadedAttention, self).__init__()\n","        self.head_count = head_count\n","\n","        self.linear_keys = nn.Linear(model_dim,\n","                                     head_count * self.dim_per_head)\n","        self.linear_values = nn.Linear(model_dim,\n","                                       head_count * self.dim_per_head)\n","        self.linear_query = nn.Linear(model_dim,\n","                                      head_count * self.dim_per_head)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.use_final_linear = use_final_linear\n","        if (self.use_final_linear):\n","            self.final_linear = nn.Linear(model_dim, model_dim)\n","\n","    def forward(self, key, value, query, mask=None,\n","                layer_cache=None, type=None, predefined_graph_1=None):\n","        \"\"\"\n","        Compute the context vector and the attention vectors.\n","\n","        Args:\n","           key (`FloatTensor`): set of `key_len`\n","                key vectors `[batch, key_len, dim]`\n","           value (`FloatTensor`): set of `key_len`\n","                value vectors `[batch, key_len, dim]`\n","           query (`FloatTensor`): set of `query_len`\n","                 query vectors  `[batch, query_len, dim]`\n","           mask: binary mask indicating which keys have\n","                 non-zero attention `[batch, query_len, key_len]`\n","        Returns:\n","           (`FloatTensor`, `FloatTensor`) :\n","\n","           * output context vectors `[batch, query_len, dim]`\n","           * one of the attention vectors `[batch, query_len, key_len]`\n","        \"\"\"\n","\n","        batch_size = key.size(0)\n","        dim_per_head = self.dim_per_head\n","        head_count = self.head_count\n","        key_len = key.size(1)\n","        query_len = query.size(1)\n","\n","        def shape(x):\n","            \"\"\"  projection \"\"\"\n","            return x.view(batch_size, -1, head_count, dim_per_head) \\\n","                .transpose(1, 2)\n","\n","        def unshape(x):\n","            \"\"\"  compute context \"\"\"\n","            return x.transpose(1, 2).contiguous() \\\n","                .view(batch_size, -1, head_count * dim_per_head)\n","\n","        # 1) Project key, value, and query.\n","        if layer_cache is not None:\n","            if type == \"self\":\n","                query, key, value = self.linear_query(query), \\\n","                                    self.linear_keys(query), \\\n","                                    self.linear_values(query)\n","\n","                key = shape(key)\n","                value = shape(value)\n","\n","                if layer_cache is not None:\n","                    device = key.device\n","                    if layer_cache[\"self_keys\"] is not None:\n","                        key = torch.cat(\n","                            (layer_cache[\"self_keys\"].to(device), key),\n","                            dim=2)\n","                    if layer_cache[\"self_values\"] is not None:\n","                        value = torch.cat(\n","                            (layer_cache[\"self_values\"].to(device), value),\n","                            dim=2)\n","                    layer_cache[\"self_keys\"] = key\n","                    layer_cache[\"self_values\"] = value\n","            elif type == \"context\":\n","                query = self.linear_query(query)\n","                if layer_cache is not None:\n","                    if layer_cache[\"memory_keys\"] is None:\n","                        key, value = self.linear_keys(key), \\\n","                                     self.linear_values(value)\n","                        key = shape(key)\n","                        value = shape(value)\n","                    else:\n","                        key, value = layer_cache[\"memory_keys\"], \\\n","                                     layer_cache[\"memory_values\"]\n","                    layer_cache[\"memory_keys\"] = key\n","                    layer_cache[\"memory_values\"] = value\n","                else:\n","                    key, value = self.linear_keys(key), \\\n","                                 self.linear_values(value)\n","                    key = shape(key)\n","                    value = shape(value)\n","        else:\n","            key = self.linear_keys(key)\n","            value = self.linear_values(value)\n","            query = self.linear_query(query)\n","            key = shape(key)\n","            value = shape(value)\n","\n","        query = shape(query)\n","\n","        key_len = key.size(2)\n","        query_len = query.size(2)\n","\n","        # 2) Calculate and scale scores.\n","        query = query / math.sqrt(dim_per_head)\n","        scores = torch.matmul(query, key.transpose(2, 3))\n","\n","        if mask is not None:\n","            mask = mask.unsqueeze(1).expand_as(scores)\n","            scores = scores.masked_fill(mask, -1e18) # how can i fix it to use fp16...\n","\n","        # 3) Apply attention dropout and compute context vectors.\n","\n","        attn = self.softmax(scores)\n","\n","        if (not predefined_graph_1 is None):\n","            attn_masked = attn[:, -1] * predefined_graph_1\n","            attn_masked = attn_masked / (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n","\n","            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n","\n","        drop_attn = self.dropout(attn)\n","        if (self.use_final_linear):\n","            context = unshape(torch.matmul(drop_attn, value))\n","            output = self.final_linear(context)\n","            return output\n","        else:\n","            context = torch.matmul(drop_attn, value)\n","            return context\n"]},{"cell_type":"code","execution_count":27,"id":"gxD37HEmG7pS","metadata":{"executionInfo":{"elapsed":750,"status":"ok","timestamp":1735038310981,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"gxD37HEmG7pS"},"outputs":[],"source":["class Summarizer(pl.LightningModule):  # 요약 모델\n","    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n","        super().__init__()\n","        self.max_pos = 512\n","        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, add_pooling_layer=False)\n","        self.ext_layer = ExtTransformerEncoder()\n","        self.n_training_steps = n_training_steps\n","        self.n_warmup_steps = n_warmup_steps\n","        self.loss = nn.BCELoss(reduction='none')\n","\n","        # Outputs for train and validation steps\n","        self.training_step_outputs = []  # 추가\n","        self.validation_step_outputs = []  # 추가\n","\n","        for p in self.ext_layer.parameters():\n","            if p.dim() > 1:\n","                xavier_uniform_(p)\n","\n","    def forward(self, src, segs, clss, labels=None):\n","        # torch 버전에 따라 처리 다름\n","        mask_src = ~(src == 0)  # 1 - (src == 0)\n","        mask_cls = ~(clss == -1)  # 1 - (clss == -1)\n","\n","        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n","        top_vec = top_vec.last_hidden_state\n","\n","        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n","        sents_vec = sents_vec * mask_cls[:, :, None].float()\n","\n","        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n","\n","        loss = 0\n","        if labels is not None:\n","            loss = self.loss(sent_scores, labels)\n","            loss = (loss * mask_cls.float()).sum() / len(labels)\n","\n","        return loss, sent_scores\n","\n","    def step(self, batch):\n","        src = batch['src']\n","        labels = batch['labels'] if 'labels' in batch and len(batch['labels']) > 0 else None\n","        segs = batch['segs']\n","        clss = batch['clss']\n","\n","        loss, sent_scores = self(src, segs, clss, labels)\n","\n","        return loss, sent_scores, labels\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, sent_scores, labels = self.step(batch)\n","        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n","        self.training_step_outputs.append({'loss': loss, 'predictions': sent_scores, 'labels': labels})\n","        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, sent_scores, labels = self.step(batch)\n","        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n","        self.validation_step_outputs.append({'loss': loss, 'predictions': sent_scores, 'labels': labels})\n","        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, sent_scores, labels = self.step(batch)\n","        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n","        return {\"loss\": loss, \"predictions\": sent_scores, \"labels\": labels}\n","\n","    def acc_loss(self, outputs):\n","        if len(outputs) == 0:\n","            return 0.0, 0.0  # 데이터가 없으면 기본값 반환\n","\n","        total_loss = 0\n","        hit_cnt = 0\n","        for outp in outputs:\n","            labels = outp['labels'].cpu()\n","            predictions, idxs = outp['predictions'].cpu().sort()\n","            loss = outp['loss'].cpu()\n","\n","            for label, idx in zip(labels, idxs):\n","                for i in range(1, 3):\n","                    if label[idx[-i - 1]] == 1:\n","                        hit_cnt += 1\n","\n","            total_loss += loss\n","\n","        avg_loss = total_loss / len(outputs)\n","        acc = hit_cnt / (3 * len(outputs) * len(labels)) if len(labels) > 0 else 0.0\n","        return acc, avg_loss\n","\n","    def on_train_epoch_end(self):\n","        acc, avg_loss = self.acc_loss(self.training_step_outputs)\n","\n","        print('acc:', acc, 'avg_loss:', avg_loss)\n","\n","        self.log('avg_train_loss', avg_loss, prog_bar=True, logger=True)\n","\n","        # Clear the outputs list for the next epoch\n","        self.training_step_outputs.clear()\n","\n","    def on_validation_epoch_end(self):\n","        acc, avg_loss = self.acc_loss(self.validation_step_outputs)\n","\n","        print('val_acc:', acc, 'avg_val_loss:', avg_loss)\n","\n","        self.log('avg_val_loss', avg_loss, prog_bar=True, logger=True)\n","\n","        # Clear the outputs list for the next epoch\n","        self.validation_step_outputs.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=2e-5)\n","\n","        steps_per_epoch = len(train_df) // BATCH_SIZE\n","        total_training_steps = steps_per_epoch * N_EPOCHS\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=steps_per_epoch,\n","            num_training_steps=total_training_steps\n","        )\n","\n","        return dict(\n","            optimizer=optimizer,\n","            lr_scheduler=dict(\n","                scheduler=scheduler,\n","                interval='step'\n","            )\n","        )"]},{"cell_type":"code","execution_count":19,"id":"e30da453","metadata":{"executionInfo":{"elapsed":1707,"status":"ok","timestamp":1735036569683,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"e30da453"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of BertModel were not initialized from the model checkpoint at /home/lhch9550/공모전 and are newly initialized: ['encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = Summarizer()"]},{"cell_type":"markdown","id":"7080fda4","metadata":{"id":"7080fda4"},"source":["# training"]},{"cell_type":"code","execution_count":109,"id":"b1e65bc9","metadata":{"executionInfo":{"elapsed":507,"status":"ok","timestamp":1735036577570,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"b1e65bc9"},"outputs":[],"source":["#linux\n","!rm -rf lightning_logs/\n","!rm -rf checkpoints/"]},{"cell_type":"code","execution_count":22,"id":"b5b6e839","metadata":{"executionInfo":{"elapsed":614,"status":"ok","timestamp":1735036581255,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"b5b6e839"},"outputs":[],"source":["checkpoint_callback = ModelCheckpoint(\n","    dirpath=\"checkpoints\",\n","    filename=\"best-checkpoint\",\n","    save_top_k=1,\n","    verbose=True,\n","    monitor=\"avg_val_loss\",\n","    mode=\"min\"\n",")"]},{"cell_type":"code","execution_count":23,"id":"9fc1f33e","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036583727,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"9fc1f33e"},"outputs":[],"source":["logger = TensorBoardLogger(\"lightning_logs\", name=\"kpfBERT_Summary\")"]},{"cell_type":"code","execution_count":24,"id":"05fd8ce8","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036583727,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"05fd8ce8"},"outputs":[],"source":["early_stopping_callback = EarlyStopping(monitor='avg_val_loss', patience=10)"]},{"cell_type":"code","execution_count":25,"id":"w5wDRXJCBFQf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1735036585738,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"w5wDRXJCBFQf","outputId":"9d124b44-a2bf-4082-cb5b-07637eff5c25"},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n"]}],"source":["trainer = pl.Trainer(\n","    logger=logger,\n","    callbacks=[early_stopping_callback],\n","    max_epochs=N_EPOCHS,\n","    accelerator=\"gpu\",  # GPU 사용\n","    devices=1           # GPU 장치 1개 사용\n",")"]},{"cell_type":"code","execution_count":null,"id":"7a767f0d","metadata":{},"outputs":[],"source":["trainer.fit(model, data_module)"]},{"cell_type":"code","execution_count":null,"id":"dcce0bbd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["a936295363c64091a6822611672539be","6b089a1e3c83422483de46e15c962bc3","77b7afe6d6074164a0e3428cf4a7bfa1","33fa757151404c17b151ab56d0e2844a","1be4a6e822614bacbca7786ec565a340","79bd75bbdcc54c6bb8f731c9b0bae7e4","0e7d8609092e410b952855ad04a3df56","271ab2860fbc4d8687aa7a50f12031c0","b0a2405c6a31487391c3eaf0da9d41f3","90e32e8ffba44eb7a7de32a8dd58cd1c","e6d8ed2a5d67438d8073996db5fc9273"]},"executionInfo":{"elapsed":42840,"status":"ok","timestamp":1735038630173,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"dcce0bbd","outputId":"72f0e46d-f1cc-430c-a9c0-ad2fe9b88c4c","scrolled":true},"outputs":[],"source":["trainer.test(model, data_module)"]},{"cell_type":"markdown","id":"b64e0c54","metadata":{"id":"b64e0c54"},"source":["# predictions"]},{"cell_type":"code","execution_count":null,"id":"cd98b0a2","metadata":{},"outputs":[],"source":["trained_model = Summarizer.load_from_checkpoint(\n","    trainer.checkpoint_callback.best_model_path\n",")\n","trained_model.eval()\n","trained_model.freeze()"]},{"cell_type":"code","execution_count":34,"id":"2cef4009","metadata":{},"outputs":[{"data":{"text/plain":["''"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["trainer.checkpoint_callback.best_model_path"]},{"cell_type":"code","execution_count":29,"id":"1b793b85","metadata":{"executionInfo":{"elapsed":533,"status":"ok","timestamp":1735037848594,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"1b793b85"},"outputs":[],"source":["def data_process(text):\n","    # 문장 분리 하고,\n","    sents = kss.split_sentences(text)\n","\n","    #데이터 가공하고,\n","    tokenlist = []\n","    for sent in sents:\n","        tokenlist.append(tokenizer(\n","            text = sent,\n","            add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n","\n","    src = [] # 토크나이징 된 전체 문단\n","    labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n","    segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n","    clss = []  #[CLS]토큰의 포지션값을 지정\n","\n","    odd = 0\n","\n","    for tkns in tokenlist:\n","\n","        if odd > 1 : odd = 0\n","        clss = clss + [len(src)]\n","        src = src + tkns['input_ids']\n","        segs = segs + [odd] * len(tkns['input_ids'])\n","        odd += 1\n","\n","        #truncation\n","        if len(src) == MAX_TOKEN_COUNT:\n","            break\n","        elif len(src) > MAX_TOKEN_COUNT:\n","            src = src[:MAX_TOKEN_COUNT - 1] + [src[-1]]\n","            segs = segs[:MAX_TOKEN_COUNT]\n","            break\n","\n","    #padding\n","    if len(src) < MAX_TOKEN_COUNT:\n","        src = src + [0]*(MAX_TOKEN_COUNT - len(src))\n","        segs = segs + [0]*(MAX_TOKEN_COUNT - len(segs))\n","\n","    if len(clss) < MAX_TOKEN_COUNT:\n","        clss = clss + [-1]*(MAX_TOKEN_COUNT - len(clss))\n","\n","    return dict(\n","        sents = sents, #정답 출력을 위해...\n","        src = torch.tensor(src),\n","        segs = torch.tensor(segs),\n","        clss = torch.tensor(clss),\n","    )"]},{"cell_type":"code","execution_count":2,"id":"791d564d","metadata":{},"outputs":[],"source":["def summarize_test(text):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU 사용 가능 여부 확인\n","    data = data_process(text.replace('\\n', ''))\n","\n","    # 데이터를 모델과 동일한 장치로 이동\n","    data['src'] = data['src'].unsqueeze(0).to(device)\n","    data['segs'] = data['segs'].unsqueeze(0).to(device)\n","    data['clss'] = data['clss'].unsqueeze(0).to(device)\n","\n","    # trained_model이 실행 중인 장치 확인 후 모델 이동\n","    trained_model.to(device)\n","\n","    # trained_model에 넣어 결과값 반환\n","    _, rtn = trained_model(data['src'], data['segs'], data['clss'])\n","    rtn = rtn.squeeze()\n","\n","    # 예측 결과값을 받기 위한 프로세스\n","    rtn_sort, idx = rtn.sort(descending=True)\n","\n","    rtn_sort = rtn_sort.tolist()\n","    idx = idx.tolist()\n","\n","    # 예측 결과 중 0까지의 인덱스 찾기\n","    end_idx = rtn_sort.index(0) if 0 in rtn_sort else len(rtn_sort)\n","\n","    # 0 이전의 값들만 사용\n","    rtn_sort = rtn_sort[:end_idx]\n","    idx = idx[:end_idx]\n","\n","    # 상위 3개 문장 선택\n","    rslt = idx[:3] if len(idx) > 5 else idx\n","\n","    # 최종 요약 결과 리스트 저장\n","    summ = [data['sents'][r] for r in rslt]  # ✅ 번호 없이 문장만 리스트에 저장\n","\n","    return summ  # ✅ 요약문 리스트 반환"]},{"cell_type":"code","execution_count":3,"id":"a7ad6907","metadata":{},"outputs":[],"source":["def summarize_test(text):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU 사용 가능 여부 확인\n","    data = data_process(text.replace('\\n', ''))\n","\n","    # 데이터를 모델과 동일한 장치로 이동\n","    data['src'] = data['src'].unsqueeze(0).to(device)\n","    data['segs'] = data['segs'].unsqueeze(0).to(device)\n","    data['clss'] = data['clss'].unsqueeze(0).to(device)\n","\n","    # trained_model이 실행 중인 장치 확인 후 모델 이동\n","    trained_model.to(device)\n","\n","    # trained_model에 넣어 결과값 반환\n","    _, rtn = trained_model(data['src'], data['segs'], data['clss'])\n","    rtn = rtn.squeeze()\n","\n","    # 예측 결과값을 받기 위한 프로세스\n","    rtn_sort, idx = rtn.sort(descending=True)\n","\n","    rtn_sort = rtn_sort.tolist()\n","    idx = idx.tolist()\n","\n","    # 예측 결과 중 0까지의 인덱스 찾기\n","    end_idx = rtn_sort.index(0) if 0 in rtn_sort else len(rtn_sort)\n","\n","    # 0 이전의 값들만 사용\n","    rtn_sort = rtn_sort[:end_idx]\n","    idx = idx[:end_idx]\n","\n","    # 상위 3개 문장 선택\n","    rslt = idx[:3] if len(idx) > 3 else idx\n","\n","    # 최종 요약 결과 리스트 저장\n","    summ = [data['sents'][r] for r in rslt]  \n","\n","    return \" \".join(summ)  "]},{"cell_type":"code","execution_count":30,"id":"6be85500","metadata":{"executionInfo":{"elapsed":522,"status":"ok","timestamp":1735037853811,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"6be85500"},"outputs":[],"source":["#테스트 문장 입력\n","test_context = '''이재명 더불어민주당 대선후보는 26일 변호사비 대납 의혹과 관련, \"내가 정말로 변호사비를 불법으로 받았으면 나를 구속하라\"고 반박했다.\n","이 후보는 이날 오후 전남 신안군 응급의료 전용헬기 계류장에서 열린 '국민반상회' 후 기자들과 만나 한 시민단체 대표가 고액 수임료 의혹 증거라며 제시한 녹취록에 대해 \"조작됐다는 증거를 갖고 있고 검찰에도 제출했다. 검찰과 수사기관들은 빨리 처리하시라\"며 이같이 말했다.\n","앞서 이민구 깨어있는시민연대당 대표는 이 후보가 특정 변호사에게 수임료로 현금과 주식 등 20억원을 줬다는 의혹을 주장하며 녹취록을 제출한 바 있다. 이에 대해 송평수 선대위 부대변인은 \"허위사실\"이라며 \"깨시민당 이 대표에게 제보를 했다는 시민단체 대표 이모 씨가 제3자로부터 기부금을 받아낼 목적으로 허위사실을 녹음한 후, 이 모 변호사에게까지 접근했다. 이러한 비상식적이고 악의적인 행태는 이재명 후보에 대한 정치적 타격을 가할 목적으로 치밀하게 준비한 것\"이라고 반박했다.\n","이에 대해 이 후보는 \"그것도 조직폭력배 조작에 버금가는 조작사건이라는 게 곧 드러날 것\"이라며 \"팩트확인을 하고 언급하면 좋겠다. 당사자도 아니고 제3자들이 자기끼리 녹음한 게 가치가 있느냐\"고 반문했다.\n","그는 \"사실이 아니면 무고하고 음해하는 사람들을 무고 혐의나 공직선거법 위반으로 빨리 처리해서 처벌하시라\"며 \"선거 국면에서 하루이틀도, 한두번도 아니고 '조폭이 뇌물 줬다'는 (허위사실 유포를) 왜 아직도 처리 안 하고 있느냐\"고 검경에 불만을 드러냈다.\n","이어 \"허위사실이 드러났으면 당연히 다시는 그런 일이 없게 해야 하는 것 아닌가. 이해가 안 된다\"며 \"선거관리, 또는 범죄를 단속하는 국가기관들이 이런 식으로 허위사실 유포나 무고 행위를 방치해 정치적 공격 수단으로 쓰게 하면 안 된다\"고 했다.\n","이 후보는 또 자신이 구민주-동교동계와 접촉해 복당을 타진했다는 언론보도와 관련해선 \"구체적으로 어떤 사람을 범주별로 나눠 무슨 계, 진영으로 말하는 것은 아니다\"라며 \"시점을 언젠가 정해 벌점이니, 제재니, 제한이니 다 없애고 모두가 합류할 수 있도록 할 생각\"이라고 말했다.\n","종전에 언급했던 '대사면' 방침을 재확인한 셈이다. 그는 \"민주당에 계셨던 분, 또 민주당에 있지 않았더라도 앞으로 함께할 분들에게 계속 연락을 하고 있다\"며 \"만나고 전화하고 힘을 합치자고 권유하고 있다\"고 했다.\n","그는 \" 현재 민주당이 이미 열린민주당과의 통합을 협의하고 있다\"며 \"거기에 더해서 꼭 민주계라고 말할 필요는 없고 부패사범이나 파렴치범으로 탈당하거나 또는 제명된 사람들이 아니라면, 국가의 미래를 걱정하는 민주개혁 진영의 일원이라면 가리지 말고 과거의 어떤 일이든 그러지 말고 힘을 합치자\"고 강조했다.\n","언론보도에 따르면, 이 후보는 최근 구민주계인 정대철 전 고문과 연락을 주고 받으며 천정배, 정동영 전 의원 등 민주당을 탈당했던 옛 동교동계와 호남 인사들의 복당을 타진했다.\n","'''"]},{"cell_type":"code","execution_count":31,"id":"a1b43921","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1735037946556,"user":{"displayName":"hyeong Jae Lee","userId":"13424549157393754089"},"user_tz":-540},"id":"a1b43921","outputId":"8cab2e4e-abb6-4890-bf1b-7bb76a2b088a"},"outputs":[{"name":"stderr","output_type":"stream","text":["[Kss]: Oh! You have mecab in your environment. Kss will take this as a backend! :D\n","\n"]},{"ename":"NameError","evalue":"name 'trained_model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rtn \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(rtn)\n","Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36msummarize_test\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# trained_model이 실행 중인 장치 확인 후 모델 이동\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrained_model\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# trained_model에 넣어 결과값 반환\u001b[39;00m\n\u001b[1;32m     14\u001b[0m _, rtn \u001b[38;5;241m=\u001b[39m trained_model(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegs\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"]}],"source":["rtn = summarize_test(test_context)\n","print(rtn)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0e7d8609092e410b952855ad04a3df56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1be4a6e822614bacbca7786ec565a340":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"271ab2860fbc4d8687aa7a50f12031c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33fa757151404c17b151ab56d0e2844a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90e32e8ffba44eb7a7de32a8dd58cd1c","placeholder":"​","style":"IPY_MODEL_e6d8ed2a5d67438d8073996db5fc9273","value":" 120/? [00:41&lt;00:00,  2.87it/s]"}},"6b089a1e3c83422483de46e15c962bc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79bd75bbdcc54c6bb8f731c9b0bae7e4","placeholder":"​","style":"IPY_MODEL_0e7d8609092e410b952855ad04a3df56","value":"Testing: "}},"77b7afe6d6074164a0e3428cf4a7bfa1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_271ab2860fbc4d8687aa7a50f12031c0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0a2405c6a31487391c3eaf0da9d41f3","value":1}},"79bd75bbdcc54c6bb8f731c9b0bae7e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90e32e8ffba44eb7a7de32a8dd58cd1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a936295363c64091a6822611672539be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b089a1e3c83422483de46e15c962bc3","IPY_MODEL_77b7afe6d6074164a0e3428cf4a7bfa1","IPY_MODEL_33fa757151404c17b151ab56d0e2844a"],"layout":"IPY_MODEL_1be4a6e822614bacbca7786ec565a340"}},"b0a2405c6a31487391c3eaf0da9d41f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6d8ed2a5d67438d8073996db5fc9273":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}
