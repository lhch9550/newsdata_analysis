# KPF-BERT 및 KeyBERT 모듈을 활용한 뉴스 기사 키워드 추출

KeyBERT는 **BERT 임베딩을 활용하여 문서에서 의미적으로 중요한 키워드를 추출하는 모델**입니다.

## 1. 주요 기능
- **문서 임베딩**: BERT를 활용하여 문서 수준 임베딩을 생성. 임베딩 모델로는 KPF-BERT를 사용하였습니다. 
- **키워드 후보군 생성**: 다양한 **N-gram** 단위를 고려하여 단어 및 구(phrase)를 벡터화
- **코사인 유사도 계산**: 문서와의 유사도를 비교하여 최적의 키워드 선정
- **MMR(Maximal Marginal Relevance) 알고리즘 적용**: 연관성과 다양성을 고려한 최적의 키워드 집합 추출

## 2. 키워드 추출 플로우
1. **문서 임베딩 생성** (BERT 기반)
2. **키워드 후보군 벡터화** (N-gram 고려)
3. **코사인 유사도를 활용한 키워드-문서 간 관계 분석**
4. **MMR 알고리즘을 활용한 최적 키워드 추출**

## 3. 핵심 알고리즘
### MMR (Maximal Marginal Relevance)
- 문서와 가장 유사한 키워드 1개를 우선 선정
- 이후, **선정된 키워드와 유사하지 않으면서도 문서와 연관성이 높은 키워드**를 반복 선정
- 다양성 조절 파라미터 (diversity=0.2)를 적용하여 특정 키워드에 집중되지 않도록 제어

### (비교) Max Sum Similarity
- 문서와 가장 유사한 키워드 후보군 선정
- 후보군 내에서 **키워드 간 유사성이 가장 낮은 조합을 최종 키워드로 선택**
- 중복되는 키워드를 제거하여 다양한 의미를 포함하는 키워드 세트 구축

## 4. 실험 방법
### 실험 환경
- **모델**: 사용자 정의 BERT 모델 (Kpf-BERT)
- **토크나이저**: 사용자 정의 BERT 토크나이저
- **형태소 분석기**: Kiwi (한국어 형태소 분석기)

### 데이터 전처리 (Preprocessing)
- Kiwi 형태소 분석기를 이용하여 **명사(NNG, NNP)만 추출**
- CountVectorizer를 활용하여 **키워드 후보군 생성**

### BERT 임베딩 적용
- **사용자 정의 BERT 모델 및 토크나이저**를 사용하여 텍스트를 벡터(임베딩)로 변환
- **문서 및 키워드 후보군을 BERT 임베딩 벡터로 변환 (Mean Pooling 적용)**

### 코사인 유사도 계산
- 문서 임베딩과 키워드 후보군 임베딩 간 **코사인 유사도 계산**
- 키워드 후보군 간의 유사도도 함께 계산하여 MMR 알고리즘 적용

### 키워드 최적화
- MMR (Maximal Marginal Relevance) 적용하여 **연관성이 높고 중복이 적은 키워드 선정**

## 4. 기대 효과
- **문서의 핵심 키워드(명사)를 추출** 가능
- **BERT 기반 의미론적 키워드 추출을 통해 기존 TF-IDF 방식 대비 높은 성능 확보**
- **핵심 키워드를 기반으로 한 여러 분석 기법 적용(예: 토픽모델링)을 위한 재료 확보**

## 참고 자료
- [KeyBERT 공식 문서](https://github.com/MaartenGr/KeyBERT)
- [BERT 기반 키워드 추출 알고리즘 개요](https://heeya-stupidbutstudying.tistory.com/entry/DL-keyword-extraction-with-KeyBERT-%EA%B0%9C%EC%9A%94%EC%99%80-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-1)


