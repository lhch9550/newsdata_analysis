{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Text after cleaning:\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    BertConfig, AutoTokenizer, BertForSequenceClassification, AdamW\n",
    ")\n",
    "\n",
    "# í‰ê°€ ê´€ë ¨ (F1 Score, Classification Report)\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "# Config ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import config\n",
    "\n",
    "# ë¼ë²¨ ë³€í™˜ ê´€ë ¨ ëª¨ë“ˆ\n",
    "import label\n",
    "\n",
    "# ë°ì´í„°ì…‹ ê´€ë ¨ ëª¨ë“ˆ\n",
    "import Dataset\n",
    "\n",
    "sys.path.append('/home/lhch9550/ê³µëª¨ì „/KPF-BERT-CLS')\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "data = pd.read_csv('/home/lhch9550/ê³µëª¨ì „/KPF-BERT-CLS/processed_data.csv')  \n",
    "print(\"Data loaded!\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ í´ë¦¬ë‹ í•¨ìˆ˜ ì •ì˜\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z-.]+)\", \"\", text)  # ì´ë©”ì¼ ì œê±°\n",
    "    text = re.sub(\"[\\r\\n\\xa0]\", \"\", text)  # ì¤„ ë°”ê¿ˆ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    text = re.sub(\"(\\.\\s+[ã„±-ã…ê°€-í£]+\\s[ê¸°]+[ì]+)\", \"\", text)  # íŠ¹ì •í•œ ë¬¸ì¥ íŒ¨í„´ ì œê±°\n",
    "    text = re.sub(\"[^\\w\\s^.]\", \" \", text)  # ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±ì„ ì œì™¸í•œ ë¬¸ì ì œê±°\n",
    "    return text\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì ìš©\n",
    "data['NEWS_CNTS'] = data['NEWS_CNTS'].apply(clean_text)\n",
    "print(\"Text after cleaning:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ì˜ ì†Œë¶„ë¥˜ ë¼ë²¨\n",
    "small_label = ['êµ­íšŒ_ì •ë‹¹', 'ë¶í•œ', 'ì„ ê±°', 'ì™¸êµ', 'ì²­ì™€ëŒ€', 'í–‰ì •_ìì¹˜', 'ê³¨í”„', 'ë†êµ¬_ë°°êµ¬', 'ì•¼êµ¬_ë©”ì´ì €ë¦¬ê·¸',\n",
    "               'ì•¼êµ¬_ì¼ë³¸í”„ë¡œì•¼êµ¬', 'ì˜¬ë¦¼í”½_ì•„ì‹œì•ˆê²Œì„', 'ì¶•êµ¬_ì›”ë“œì»µ', 'ì¶•êµ¬_í•œêµ­í”„ë¡œì¶•êµ¬', 'ì¶•êµ¬_í•´ì™¸ì¶•êµ¬',\n",
    "               'êµìœ¡_ì‹œí—˜', 'ë‚ ì”¨', 'ë…¸ë™_ë³µì§€', 'ë¯¸ë””ì–´', 'ì‚¬ê±´_ì‚¬ê³ ', 'ì—¬ì„±', 'ì˜ë£Œ_ê±´ê°•', 'ì¥ì• ì¸', 'í™˜ê²½',\n",
    "               'ë¯¸ìˆ _ê±´ì¶•', 'ë°©ì†¡_ì—°ì˜ˆ', 'ìƒí™œ', 'ìš”ë¦¬_ì—¬í–‰', 'ìŒì•…', 'ì „ì‹œ_ê³µì—°', 'ì¢…êµ', 'ì¶œíŒ', 'í•™ìˆ _ë¬¸í™”ì¬',\n",
    "               'ëŸ¬ì‹œì•„', 'ë¯¸êµ­_ë¶ë¯¸', 'ì•„ì‹œì•„', 'ìœ ëŸ½_EU', 'ì¼ë³¸', 'ì¤‘êµ­', 'ì¤‘ë‚¨ë¯¸', 'ì¤‘ë™_ì•„í”„ë¦¬ì¹´', 'êµ­ì œê²½ì œ',\n",
    "               'ê¸ˆìœµ_ì¬í…Œí¬', 'ë¬´ì—­', 'ë°˜ë„ì²´', 'ë¶€ë™ì‚°', 'ì‚°ì—…_ê¸°ì—…', 'ì„œë¹„ìŠ¤_ì‡¼í•‘', 'ì™¸í™˜', 'ìœ í†µ', 'ìë™ì°¨',\n",
    "               'ìì›', 'ì¦ê¶Œ_ì¦ì‹œ', 'ì·¨ì—…_ì°½ì—…', 'ê³¼í•™', 'ëª¨ë°”ì¼', 'ë³´ì•ˆ', 'ì¸í„°ë„·_SNS', 'ì½˜í…ì¸ ']\n",
    "\n",
    "# ì†Œë¶„ë¥˜ ë¼ë²¨ì— ë§ì¶˜ label2id, id2label ìƒì„±\n",
    "small_label2id = {label: i for i, label in enumerate(small_label)}\n",
    "small_id2label = {i: label for label, i in small_label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>original_topic</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>NEWS_SML_SUBJ_CD</th>\n",
       "      <th>NEWS_CNTS</th>\n",
       "      <th>label_list</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤</td>\n",
       "      <td>20220101</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ê²½ì œ&gt;ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>NIRW2300000001.10.1</td>\n",
       "      <td>ê²½ë‚¨ 12ì›”ì—ë§Œ 5698ëª… â€˜ì—­ëŒ€ ìµœë‹¤â€™â€¦29ì¼ ì—°ì† ì„¸ ìë¦¿ìˆ˜ í™•ì‚°</td>\n",
       "      <td>ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>ê²½ë‚¨ 12ì›”ì—ë§Œ 5698ëª…  ì—­ëŒ€ ìµœë‹¤  29ì¼ ì—°ì† ì„¸ ìë¦¿ìˆ˜ í™•ì‚°</td>\n",
       "      <td>['ì·¨ì—…_ì°½ì—…']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤</td>\n",
       "      <td>20220101</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ê²½ì œ&gt;ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>NIRW2300000001.10.2</td>\n",
       "      <td>ì§€ë‚œí•´ 12ì›” ê²½ë‚¨ì—ì„œ ë°œìƒí•œ ì½”ë¡œë‚˜19 í™•ì§„ìëŠ” ì—­ëŒ€ ê°€ì¥ ë§ì€ 5700ëª…ì— ë‹¬í–ˆë‹¤.</td>\n",
       "      <td>ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>ì§€ë‚œí•´ 12ì›” ê²½ë‚¨ì—ì„œ ë°œìƒí•œ ì½”ë¡œë‚˜19 í™•ì§„ìëŠ” ì—­ëŒ€ ê°€ì¥ ë§ì€ 5700ëª…ì— ë‹¬í–ˆë‹¤.</td>\n",
       "      <td>['ì·¨ì—…_ì°½ì—…']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤</td>\n",
       "      <td>20220101</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ê²½ì œ&gt;ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>NIRW2300000001.10.3</td>\n",
       "      <td>ê²½ë‚¨ì€ 1ì¼ ì˜¤ì „ 10ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë„ë‚´ 3ê°œ ì‹œì—ì„œ 21ëª…ì˜ í™•ì§„ìê°€ ë°œìƒí–ˆë‹¤. ì°½...</td>\n",
       "      <td>ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>ê²½ë‚¨ì€ 1ì¼ ì˜¤ì „ 10ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë„ë‚´ 3ê°œ ì‹œì—ì„œ 21ëª…ì˜ í™•ì§„ìê°€ ë°œìƒí–ˆë‹¤. ì°½...</td>\n",
       "      <td>['ì·¨ì—…_ì°½ì—…']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤</td>\n",
       "      <td>20220101</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ê²½ì œ&gt;ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>NIRW2300000001.10.4</td>\n",
       "      <td>ì´ ì¤‘ 38%ì¸ 8ëª…ì€ ë„ë‚´ ë˜ëŠ” ë‹¤ë¥¸ ì§€ì—­ í™•ì§„ìì˜ ì ‘ì´‰ì, 8ëª…(38%)ì€ ê°ì—¼...</td>\n",
       "      <td>ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>ì´ ì¤‘ 38 ì¸ 8ëª…ì€ ë„ë‚´ ë˜ëŠ” ë‹¤ë¥¸ ì§€ì—­ í™•ì§„ìì˜ ì ‘ì´‰ì  8ëª… 38  ì€ ê°ì—¼...</td>\n",
       "      <td>['ì·¨ì—…_ì°½ì—…']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NIRW2300000001</td>\n",
       "      <td>NIRW2300000001.10</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜</td>\n",
       "      <td>ë…¸ì»·ë‰´ìŠ¤</td>\n",
       "      <td>20220101</td>\n",
       "      <td>ì‚¬íšŒ</td>\n",
       "      <td>ê²½ì œ&gt;ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>NIRW2300000001.10.5</td>\n",
       "      <td>ê¸°ì¡´ ì§‘ë‹¨ê°ì—¼ ì‚¬ë¡€ë¥¼ ë³´ë©´, ê±°ì œ ì†Œì¬ ì¢…êµì‹œì„¤ ê´€ë ¨ í™•ì§„ìëŠ” 4ëª…ì´ ì¶”ê°€ë¼ 25ëª…...</td>\n",
       "      <td>ì·¨ì—…_ì°½ì—…</td>\n",
       "      <td>ê¸°ì¡´ ì§‘ë‹¨ê°ì—¼ ì‚¬ë¡€ë¥¼ ë³´ë©´  ê±°ì œ ì†Œì¬ ì¢…êµì‹œì„¤ ê´€ë ¨ í™•ì§„ìëŠ” 4ëª…ì´ ì¶”ê°€ë¼ 25ëª…...</td>\n",
       "      <td>['ì·¨ì—…_ì°½ì—…']</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734489</th>\n",
       "      <td>734489</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/ê³¼í•™</td>\n",
       "      <td>IT_ê³¼í•™&gt;ëª¨ë°”ì¼</td>\n",
       "      <td>NPRW2300000001.31892.7</td>\n",
       "      <td>ë‚˜ì•„ê°€, íŠ¹í—ˆì²­ì€ ì˜¬í•´ë¶€í„° WIPOì™€ í˜‘ì˜í•´ ê³ ê°ì§€ì› ì „ë¬¸ê°€ì˜ ì—­í• ì„ í™•ëŒ€í•˜ê³  êµ­ë‚´...</td>\n",
       "      <td>ëª¨ë°”ì¼</td>\n",
       "      <td>ë‚˜ì•„ê°€  íŠ¹í—ˆì²­ì€ ì˜¬í•´ë¶€í„° WIPOì™€ í˜‘ì˜í•´ ê³ ê°ì§€ì› ì „ë¬¸ê°€ì˜ ì—­í• ì„ í™•ëŒ€í•˜ê³  êµ­ë‚´...</td>\n",
       "      <td>['ëª¨ë°”ì¼']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734490</th>\n",
       "      <td>734490</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/ê³¼í•™</td>\n",
       "      <td>IT_ê³¼í•™&gt;ëª¨ë°”ì¼</td>\n",
       "      <td>NPRW2300000001.31892.8</td>\n",
       "      <td>ì•ìœ¼ë¡œ ê³ ê°ì§€ì› ì „ë¬¸ê°€ëŠ” ì¶œì›ì¸, íŠ¹í—ˆì‚¬ë¬´ì†Œ ëŒ€ë¦¬ì¸ê³¼ ê¸´ë°€í•œ ì†Œí†µì„ í†µí•´ ePCT ...</td>\n",
       "      <td>ëª¨ë°”ì¼</td>\n",
       "      <td>ì•ìœ¼ë¡œ ê³ ê°ì§€ì› ì „ë¬¸ê°€ëŠ” ì¶œì›ì¸  íŠ¹í—ˆì‚¬ë¬´ì†Œ ëŒ€ë¦¬ì¸ê³¼ ê¸´ë°€í•œ ì†Œí†µì„ í†µí•´ ePCT ...</td>\n",
       "      <td>['ëª¨ë°”ì¼']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734491</th>\n",
       "      <td>734491</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/ê³¼í•™</td>\n",
       "      <td>IT_ê³¼í•™&gt;ëª¨ë°”ì¼</td>\n",
       "      <td>NPRW2300000001.31892.9</td>\n",
       "      <td>ì´ì²˜ëŸ¼ WIPOê°€ í•œêµ­ì— ê³ ê°ì§€ì› ì „ë¬¸ê°€ë¥¼ ë°°ì¹˜í•˜ê³ , ì‚¬ìš©ì ì§€ì›ì„ ë”ìš± ê°•í™”í•˜ê¸°ë¡œ...</td>\n",
       "      <td>ëª¨ë°”ì¼</td>\n",
       "      <td>ì´ì²˜ëŸ¼ WIPOê°€ í•œêµ­ì— ê³ ê°ì§€ì› ì „ë¬¸ê°€ë¥¼ ë°°ì¹˜í•˜ê³   ì‚¬ìš©ì ì§€ì›ì„ ë”ìš± ê°•í™”í•˜ê¸°ë¡œ...</td>\n",
       "      <td>['ëª¨ë°”ì¼']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734492</th>\n",
       "      <td>734492</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/ê³¼í•™</td>\n",
       "      <td>IT_ê³¼í•™&gt;ëª¨ë°”ì¼</td>\n",
       "      <td>NPRW2300000001.31892.10</td>\n",
       "      <td>ì‹¤ì œë¡œ ì§€ë‚œí•´ ìš°ë¦¬ë‚˜ë¼ì˜ PCT êµ­ì œíŠ¹í—ˆ ì¶œì›ì€ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 3.2% ì¦ê°€í•œ 2...</td>\n",
       "      <td>ëª¨ë°”ì¼</td>\n",
       "      <td>ì‹¤ì œë¡œ ì§€ë‚œí•´ ìš°ë¦¬ë‚˜ë¼ì˜ PCT êµ­ì œíŠ¹í—ˆ ì¶œì›ì€ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 3.2  ì¦ê°€í•œ 2...</td>\n",
       "      <td>['ëª¨ë°”ì¼']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734493</th>\n",
       "      <td>734493</td>\n",
       "      <td>NPRW2300000001</td>\n",
       "      <td>NPRW2300000001.31892</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬</td>\n",
       "      <td>ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|</td>\n",
       "      <td>ë¨¸ë‹ˆíˆ¬ë°ì´</td>\n",
       "      <td>20220628</td>\n",
       "      <td>IT/ê³¼í•™</td>\n",
       "      <td>IT_ê³¼í•™&gt;ëª¨ë°”ì¼</td>\n",
       "      <td>NPRW2300000001.31892.11</td>\n",
       "      <td>ê¹€ê¸°ë²” íŠ¹í—ˆì²­ ì •ë³´ê³ ê°ì§€ì›êµ­ì¥ì€ â€œê¸°ì¡´ PCT-SAFE ì‚¬ìš©ìë“¤ì´ ë”ìš± í¸ë¦¬í•˜ê³  ì•ˆ...</td>\n",
       "      <td>ëª¨ë°”ì¼</td>\n",
       "      <td>ê¹€ê¸°ë²” íŠ¹í—ˆì²­ ì •ë³´ê³ ê°ì§€ì›êµ­ì¥ì€  ê¸°ì¡´ PCT SAFE ì‚¬ìš©ìë“¤ì´ ë”ìš± í¸ë¦¬í•˜ê³  ì•ˆ...</td>\n",
       "      <td>['ëª¨ë°”ì¼']</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487662 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         file_id                doc_id           title  \\\n",
       "0                0  NIRW2300000001     NIRW2300000001.10   ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬   \n",
       "1                1  NIRW2300000001     NIRW2300000001.10   ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬   \n",
       "2                2  NIRW2300000001     NIRW2300000001.10   ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬   \n",
       "3                3  NIRW2300000001     NIRW2300000001.10   ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬   \n",
       "4                4  NIRW2300000001     NIRW2300000001.10   ë…¸ì»·ë‰´ìŠ¤ 2022ë…„ ê¸°ì‚¬   \n",
       "...            ...             ...                   ...             ...   \n",
       "734489      734489  NPRW2300000001  NPRW2300000001.31892  ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬   \n",
       "734490      734490  NPRW2300000001  NPRW2300000001.31892  ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬   \n",
       "734491      734491  NPRW2300000001  NPRW2300000001.31892  ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬   \n",
       "734492      734492  NPRW2300000001  NPRW2300000001.31892  ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬   \n",
       "734493      734493  NPRW2300000001  NPRW2300000001.31892  ë¨¸ë‹ˆíˆ¬ë°ì´ 2022ë…„ ê¸°ì‚¬   \n",
       "\n",
       "                  author publisher      date  topic original_topic  \\\n",
       "0       ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜      ë…¸ì»·ë‰´ìŠ¤  20220101     ì‚¬íšŒ       ê²½ì œ>ì·¨ì—…_ì°½ì—…   \n",
       "1       ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜      ë…¸ì»·ë‰´ìŠ¤  20220101     ì‚¬íšŒ       ê²½ì œ>ì·¨ì—…_ì°½ì—…   \n",
       "2       ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜      ë…¸ì»·ë‰´ìŠ¤  20220101     ì‚¬íšŒ       ê²½ì œ>ì·¨ì—…_ì°½ì—…   \n",
       "3       ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜      ë…¸ì»·ë‰´ìŠ¤  20220101     ì‚¬íšŒ       ê²½ì œ>ì·¨ì—…_ì°½ì—…   \n",
       "4       ê²½ë‚¨CBS ìµœí˜¸ì˜ ê¸°ì ìµœí˜¸ì˜      ë…¸ì»·ë‰´ìŠ¤  20220101     ì‚¬íšŒ       ê²½ì œ>ì·¨ì—…_ì°½ì—…   \n",
       "...                  ...       ...       ...    ...            ...   \n",
       "734489        ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|     ë¨¸ë‹ˆíˆ¬ë°ì´  20220628  IT/ê³¼í•™      IT_ê³¼í•™>ëª¨ë°”ì¼   \n",
       "734490        ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|     ë¨¸ë‹ˆíˆ¬ë°ì´  20220628  IT/ê³¼í•™      IT_ê³¼í•™>ëª¨ë°”ì¼   \n",
       "734491        ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|     ë¨¸ë‹ˆíˆ¬ë°ì´  20220628  IT/ê³¼í•™      IT_ê³¼í•™>ëª¨ë°”ì¼   \n",
       "734492        ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|     ë¨¸ë‹ˆíˆ¬ë°ì´  20220628  IT/ê³¼í•™      IT_ê³¼í•™>ëª¨ë°”ì¼   \n",
       "734493        ëŒ€ì „=í—ˆì¬êµ¬|ê¸°ì|     ë¨¸ë‹ˆíˆ¬ë°ì´  20220628  IT/ê³¼í•™      IT_ê³¼í•™>ëª¨ë°”ì¼   \n",
       "\n",
       "                    sentence_id  \\\n",
       "0           NIRW2300000001.10.1   \n",
       "1           NIRW2300000001.10.2   \n",
       "2           NIRW2300000001.10.3   \n",
       "3           NIRW2300000001.10.4   \n",
       "4           NIRW2300000001.10.5   \n",
       "...                         ...   \n",
       "734489   NPRW2300000001.31892.7   \n",
       "734490   NPRW2300000001.31892.8   \n",
       "734491   NPRW2300000001.31892.9   \n",
       "734492  NPRW2300000001.31892.10   \n",
       "734493  NPRW2300000001.31892.11   \n",
       "\n",
       "                                                 sentence NEWS_SML_SUBJ_CD  \\\n",
       "0                  ê²½ë‚¨ 12ì›”ì—ë§Œ 5698ëª… â€˜ì—­ëŒ€ ìµœë‹¤â€™â€¦29ì¼ ì—°ì† ì„¸ ìë¦¿ìˆ˜ í™•ì‚°            ì·¨ì—…_ì°½ì—…   \n",
       "1        ì§€ë‚œí•´ 12ì›” ê²½ë‚¨ì—ì„œ ë°œìƒí•œ ì½”ë¡œë‚˜19 í™•ì§„ìëŠ” ì—­ëŒ€ ê°€ì¥ ë§ì€ 5700ëª…ì— ë‹¬í–ˆë‹¤.            ì·¨ì—…_ì°½ì—…   \n",
       "2       ê²½ë‚¨ì€ 1ì¼ ì˜¤ì „ 10ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë„ë‚´ 3ê°œ ì‹œì—ì„œ 21ëª…ì˜ í™•ì§„ìê°€ ë°œìƒí–ˆë‹¤. ì°½...            ì·¨ì—…_ì°½ì—…   \n",
       "3       ì´ ì¤‘ 38%ì¸ 8ëª…ì€ ë„ë‚´ ë˜ëŠ” ë‹¤ë¥¸ ì§€ì—­ í™•ì§„ìì˜ ì ‘ì´‰ì, 8ëª…(38%)ì€ ê°ì—¼...            ì·¨ì—…_ì°½ì—…   \n",
       "4       ê¸°ì¡´ ì§‘ë‹¨ê°ì—¼ ì‚¬ë¡€ë¥¼ ë³´ë©´, ê±°ì œ ì†Œì¬ ì¢…êµì‹œì„¤ ê´€ë ¨ í™•ì§„ìëŠ” 4ëª…ì´ ì¶”ê°€ë¼ 25ëª…...            ì·¨ì—…_ì°½ì—…   \n",
       "...                                                   ...              ...   \n",
       "734489  ë‚˜ì•„ê°€, íŠ¹í—ˆì²­ì€ ì˜¬í•´ë¶€í„° WIPOì™€ í˜‘ì˜í•´ ê³ ê°ì§€ì› ì „ë¬¸ê°€ì˜ ì—­í• ì„ í™•ëŒ€í•˜ê³  êµ­ë‚´...              ëª¨ë°”ì¼   \n",
       "734490  ì•ìœ¼ë¡œ ê³ ê°ì§€ì› ì „ë¬¸ê°€ëŠ” ì¶œì›ì¸, íŠ¹í—ˆì‚¬ë¬´ì†Œ ëŒ€ë¦¬ì¸ê³¼ ê¸´ë°€í•œ ì†Œí†µì„ í†µí•´ ePCT ...              ëª¨ë°”ì¼   \n",
       "734491  ì´ì²˜ëŸ¼ WIPOê°€ í•œêµ­ì— ê³ ê°ì§€ì› ì „ë¬¸ê°€ë¥¼ ë°°ì¹˜í•˜ê³ , ì‚¬ìš©ì ì§€ì›ì„ ë”ìš± ê°•í™”í•˜ê¸°ë¡œ...              ëª¨ë°”ì¼   \n",
       "734492  ì‹¤ì œë¡œ ì§€ë‚œí•´ ìš°ë¦¬ë‚˜ë¼ì˜ PCT êµ­ì œíŠ¹í—ˆ ì¶œì›ì€ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 3.2% ì¦ê°€í•œ 2...              ëª¨ë°”ì¼   \n",
       "734493  ê¹€ê¸°ë²” íŠ¹í—ˆì²­ ì •ë³´ê³ ê°ì§€ì›êµ­ì¥ì€ â€œê¸°ì¡´ PCT-SAFE ì‚¬ìš©ìë“¤ì´ ë”ìš± í¸ë¦¬í•˜ê³  ì•ˆ...              ëª¨ë°”ì¼   \n",
       "\n",
       "                                                NEWS_CNTS label_list  label  \n",
       "0                  ê²½ë‚¨ 12ì›”ì—ë§Œ 5698ëª…  ì—­ëŒ€ ìµœë‹¤  29ì¼ ì—°ì† ì„¸ ìë¦¿ìˆ˜ í™•ì‚°  ['ì·¨ì—…_ì°½ì—…']   52.0  \n",
       "1        ì§€ë‚œí•´ 12ì›” ê²½ë‚¨ì—ì„œ ë°œìƒí•œ ì½”ë¡œë‚˜19 í™•ì§„ìëŠ” ì—­ëŒ€ ê°€ì¥ ë§ì€ 5700ëª…ì— ë‹¬í–ˆë‹¤.  ['ì·¨ì—…_ì°½ì—…']   52.0  \n",
       "2       ê²½ë‚¨ì€ 1ì¼ ì˜¤ì „ 10ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë„ë‚´ 3ê°œ ì‹œì—ì„œ 21ëª…ì˜ í™•ì§„ìê°€ ë°œìƒí–ˆë‹¤. ì°½...  ['ì·¨ì—…_ì°½ì—…']   52.0  \n",
       "3       ì´ ì¤‘ 38 ì¸ 8ëª…ì€ ë„ë‚´ ë˜ëŠ” ë‹¤ë¥¸ ì§€ì—­ í™•ì§„ìì˜ ì ‘ì´‰ì  8ëª… 38  ì€ ê°ì—¼...  ['ì·¨ì—…_ì°½ì—…']   52.0  \n",
       "4       ê¸°ì¡´ ì§‘ë‹¨ê°ì—¼ ì‚¬ë¡€ë¥¼ ë³´ë©´  ê±°ì œ ì†Œì¬ ì¢…êµì‹œì„¤ ê´€ë ¨ í™•ì§„ìëŠ” 4ëª…ì´ ì¶”ê°€ë¼ 25ëª…...  ['ì·¨ì—…_ì°½ì—…']   52.0  \n",
       "...                                                   ...        ...    ...  \n",
       "734489  ë‚˜ì•„ê°€  íŠ¹í—ˆì²­ì€ ì˜¬í•´ë¶€í„° WIPOì™€ í˜‘ì˜í•´ ê³ ê°ì§€ì› ì „ë¬¸ê°€ì˜ ì—­í• ì„ í™•ëŒ€í•˜ê³  êµ­ë‚´...    ['ëª¨ë°”ì¼']   54.0  \n",
       "734490  ì•ìœ¼ë¡œ ê³ ê°ì§€ì› ì „ë¬¸ê°€ëŠ” ì¶œì›ì¸  íŠ¹í—ˆì‚¬ë¬´ì†Œ ëŒ€ë¦¬ì¸ê³¼ ê¸´ë°€í•œ ì†Œí†µì„ í†µí•´ ePCT ...    ['ëª¨ë°”ì¼']   54.0  \n",
       "734491  ì´ì²˜ëŸ¼ WIPOê°€ í•œêµ­ì— ê³ ê°ì§€ì› ì „ë¬¸ê°€ë¥¼ ë°°ì¹˜í•˜ê³   ì‚¬ìš©ì ì§€ì›ì„ ë”ìš± ê°•í™”í•˜ê¸°ë¡œ...    ['ëª¨ë°”ì¼']   54.0  \n",
       "734492  ì‹¤ì œë¡œ ì§€ë‚œí•´ ìš°ë¦¬ë‚˜ë¼ì˜ PCT êµ­ì œíŠ¹í—ˆ ì¶œì›ì€ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 3.2  ì¦ê°€í•œ 2...    ['ëª¨ë°”ì¼']   54.0  \n",
       "734493  ê¹€ê¸°ë²” íŠ¹í—ˆì²­ ì •ë³´ê³ ê°ì§€ì›êµ­ì¥ì€  ê¸°ì¡´ PCT SAFE ì‚¬ìš©ìë“¤ì´ ë”ìš± í¸ë¦¬í•˜ê³  ì•ˆ...    ['ëª¨ë°”ì¼']   54.0  \n",
       "\n",
       "[487662 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¼ë²¨ ë³€í™˜ í•¨ìˆ˜ ì •ì˜\n",
    "def label_to_id(label):\n",
    "    \"\"\"ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì²« ë²ˆì§¸ ë¼ë²¨ë§Œ ì„ íƒí•˜ê³ , í•´ë‹¹ ë¼ë²¨ì„ label2idë¡œ ë³€í™˜\"\"\"\n",
    "    first_label = label.split(',')[0].strip()  # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì²« ë²ˆì§¸ ë¼ë²¨ë§Œ ì„ íƒ\n",
    "    \n",
    "    if first_label in small_label2id:\n",
    "        return small_label2id[first_label]  # í•´ë‹¹ ë¼ë²¨ì„ IDë¡œ ë³€í™˜\n",
    "    else:\n",
    "        #print(f\"Label '{first_label}' not found in label2id.\")  # ë””ë²„ê¹… ë©”ì‹œì§€\n",
    "        return None  # ë¼ë²¨ì´ ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "\n",
    "# 'NEWS_SML_SUBJ_CD' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë¼ë²¨ì„ ìˆ«ì IDë¡œ ë³€í™˜\n",
    "data['label'] = data['NEWS_SML_SUBJ_CD'].apply(label_to_id)\n",
    "\n",
    "# NaN ê°’ì´ ìˆëŠ” í–‰ì„ ë“œë\n",
    "data = data.dropna(subset=['label'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ë°ì´í„° ìƒ˜í”Œë§ í•¨ìˆ˜\n",
    "def sampling_func(data, sample_pct, _seed):\n",
    "    np.random.seed(_seed)\n",
    "    N = len(data)  # ë°ì´í„° ê¸¸ì´\n",
    "    sample_n = int(N * sample_pct)  # ìƒ˜í”Œë§í•  ë°ì´í„° ìˆ˜\n",
    "    # DataFrameì—ì„œ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§\n",
    "    sample = data.sample(n=sample_n, random_state=_seed)  # pandas sample ì‚¬ìš©\n",
    "    return sample\n",
    "\n",
    "# ClsDataset í´ë˜ìŠ¤ ì •ì˜\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # ìƒ˜í”Œë§ëœ ë°ì´í„°\n",
    "        # ë°ì´í„°ì—ì„œ 'NEWS_CNTS'ì™€ 'label'ì„ ë¶„ë¦¬\n",
    "        self.texts = data['NEWS_CNTS'].tolist()  # DataFrameì—ì„œ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.labels = data['label'].tolist()  # DataFrameì—ì„œ ë¼ë²¨ ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # í…ìŠ¤íŠ¸ì™€ ë¼ë²¨ì„ ë°˜í™˜\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label\n",
    "\n",
    "# ìˆ˜ì •ëœ load_dataset í•¨ìˆ˜\n",
    "def load_dataset(data, con):\n",
    "    # ê²°ì¸¡ê°’ ì²˜ë¦¬: 'label' ì»¬ëŸ¼ì— NaN ê°’ì´ ìˆëŠ” í–‰ì€ ì œê±°\n",
    "    data = data.dropna(subset=['label'])\n",
    "    \n",
    "    # 'label' ì»¬ëŸ¼ì— NaN ì²˜ë¦¬ ë° ì •ìˆ˜ ê°’ ë³€í™˜\n",
    "    data['label'] = data['label'].apply(lambda x: int(x) if isinstance(x, (int, float)) else 0)\n",
    "    \n",
    "    # num_labelsë¡œ ì„¤ì •í•œ ë²”ìœ„ ë‚´ë¡œ ë¼ë²¨ ê°’ ì œí•œ (ì˜ˆ: 0ì—ì„œ num_labels-1 ì‚¬ì´)\n",
    "    data['label'] = data['label'].apply(lambda x: max(0, min(x, con.num_labels - 1)))\n",
    "\n",
    "    # ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •: train, valid, test ë¶„í• \n",
    "    train_pct = 0.7  # train ë¹„ìœ¨\n",
    "    valid_pct = 0.2  # valid ë¹„ìœ¨\n",
    "    test_pct = 0.1   # test ë¹„ìœ¨\n",
    "\n",
    "    # ë°ì´í„°ì—ì„œ 'train', 'valid', 'test'ë¡œ ë¶„í• \n",
    "    train_data = data.groupby('label', group_keys=False).apply(sampling_func, sample_pct=train_pct, _seed=con.seed)\n",
    "    train_data.sort_index()\n",
    "\n",
    "    # valid ë°ì´í„°ëŠ” train ë°ì´í„°ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ì—ì„œ ìƒ˜í”Œë§\n",
    "    last_data = data.loc[~data.index.isin(train_data.index)].reset_index(drop=True)\n",
    "    valid_data = last_data.groupby('label', group_keys=False).apply(sampling_func, sample_pct=valid_pct/(valid_pct + test_pct), _seed=con.seed)\n",
    "\n",
    "    # test ë°ì´í„°ëŠ” valid ë°ì´í„°ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ì—ì„œ ì¶”ì¶œ\n",
    "    test_data = last_data.loc[~last_data.index.isin(valid_data.index)].reset_index(drop=True)\n",
    "\n",
    "    # ê° ë°ì´í„°ì…‹ í¬ê¸° ì¶œë ¥ (ë””ë²„ê¹…ìš©)\n",
    "    print(f\"Train data size: {len(train_data)}\")\n",
    "    print(f\"Valid data size: {len(valid_data)}\")\n",
    "    print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "    # DataLoader ì¤€ë¹„\n",
    "    train_dataset = ClsDataset(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=con.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    valid_dataset = ClsDataset(valid_data)\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=con.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    test_dataset = ClsDataset(test_data)\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=con.batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import BertConfig, BertForSequenceClassification, AutoTokenizer, AdamW\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config í´ë˜ìŠ¤ë¥¼ í†µí•´ ì„¤ì •ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "from config import Config\n",
    "_config = Config()\n",
    "_config.num_labels = len(data['label'].unique())  # ë¼ë²¨ì˜ ê³ ìœ  ê°œìˆ˜ë¥¼ ì„¤ì •\n",
    "\n",
    "# ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
    "def initialize_model(con, label2id):\n",
    "    model = BertForSequenceClassification.from_pretrained(con.model_name, num_labels=len(small_label2id),ignore_mismatched_sizes=True)\n",
    "    model.to(con.device)  # ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
    "    tokenizer = AutoTokenizer.from_pretrained(con.model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "def set_optimizer(model, con):\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': model.bert.parameters(), 'lr': 3e-5},\n",
    "        {'params': model.classifier.parameters(), 'lr': con.learning_rate}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=con.learning_rate, eps=con.adam_epsilon, no_deprecation_warning=True)\n",
    "    return optimizer\n",
    "\n",
    "# í•™ìŠµ, í‰ê°€, í…ŒìŠ¤íŠ¸ ì—í¬í¬ í•¨ìˆ˜\n",
    "from tqdm import tqdm\n",
    "\n",
    "# train_epochì— tqdm ì ìš©\n",
    "def train_epoch(epoch, model, dataloader, optimizer, tokenizer, con):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} Training\", unit=\"batch\")  \n",
    "\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        text_inputs = [str(text) if isinstance(text, (str, int, float)) else \"\" for text in batch[0]]\n",
    "\n",
    "        sample = tokenizer(\n",
    "            text_inputs, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=con.max_seq_len, \n",
    "            return_tensors=\"pt\", \n",
    "            return_token_type_ids=False, \n",
    "            return_attention_mask=True,  # \n",
    "            return_offsets_mapping=False\n",
    "        )['input_ids']\n",
    "\n",
    "        _label = batch[1].to(con.device)\n",
    "        samples = sample.to(con.device)\n",
    "        labels = torch.tensor(_label).to(con.device)  #\n",
    "\n",
    "        outputs = model(samples, labels=labels)\n",
    "        loss = outputs.loss  # \n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), con.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def valid_epoch(epoch, dataloader, model, tokenizer, con, id2label):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_len = 0\n",
    "    model.eval()\n",
    "    all_token_predictions = []\n",
    "    all_token_labels = []\n",
    "    \n",
    "    tepoch = tqdm(dataloader, unit=\"batch\", leave=False)\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(f\"Valid\")\n",
    "        with torch.no_grad():\n",
    "            sample = tokenizer(batch[0], padding='max_length', truncation=True, stride=con.stride,\n",
    "                               max_length=con.max_seq_len, return_tensors=\"pt\")['input_ids']\n",
    "            _label = batch[1].to(con.device)\n",
    "            samples = sample.to(con.device)\n",
    "            labels = torch.tensor(_label).to(con.device)\n",
    "\n",
    "            outputs = model(samples, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            all_token_labels.extend(labels.cpu().numpy())\n",
    "            all_token_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        tepoch.set_postfix(loss=loss.mean().item())\n",
    "    \n",
    "    # F1 Score ê³„ì‚°\n",
    "    all_token_labels = [id2label[int(x)] for x in all_token_labels]\n",
    "    all_token_predictions = [id2label[int(x)] for x in all_token_predictions]\n",
    "    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"micro\")\n",
    "    print('[Epoch {}] -> F1_score: {:.4f}, Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, token_f1, total_loss / len(dataloader), total_correct / total_len))\n",
    "    \n",
    "    return total_loss / len(dataloader), token_f1\n",
    "\n",
    "def test_epoch(dataloader, model, tokenizer, con, id2label):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_len = 0\n",
    "    model.eval()\n",
    "    all_token_predictions = []\n",
    "    all_token_labels = []\n",
    "    \n",
    "    tepoch = tqdm(dataloader, unit=\"batch\", leave=False)\n",
    "    for batch in tepoch:\n",
    "        tepoch.set_description(f\"Test\")\n",
    "        with torch.no_grad():\n",
    "            sample = tokenizer(batch[0], padding='max_length', truncation=True, stride=con.stride,\n",
    "                               max_length=con.max_seq_len, return_tensors=\"pt\")['input_ids']\n",
    "            _label = batch[1].to(con.device)\n",
    "            samples = sample.to(con.device)\n",
    "            labels = torch.tensor(_label).to(con.device)\n",
    "            \n",
    "            outputs = model(samples, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            all_token_labels.extend(labels.cpu().numpy())\n",
    "            all_token_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        tepoch.set_postfix(loss=loss.mean().item())\n",
    "    \n",
    "    # F1 Score ê³„ì‚° ë° ë³´ê³ ì„œ ì¶œë ¥\n",
    "    all_token_labels = [id2label[int(x)] for x in all_token_labels]\n",
    "    all_token_predictions = [id2label[int(x)] for x in all_token_predictions]\n",
    "    token_result = classification_report(all_token_labels, all_token_predictions)\n",
    "    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"micro\")\n",
    "\n",
    "    print(token_result)\n",
    "    tepoch.set_postfix(loss=total_loss / len(dataloader), token_f1=token_f1)\n",
    "\n",
    "    return total_loss / len(dataloader), token_f1\n",
    "\n",
    "# í•™ìŠµ ê³¼ì •\n",
    "def train(model, tokenizer, train_dataloader, valid_dataloader, test_dataloader, optimizer, con, small_id2label):\n",
    "    for epoch in range(con.epoch):\n",
    "        print(f\"Epoch {epoch+1}/{con.epoch}\")\n",
    "        \n",
    "        # í•™ìŠµ\n",
    "        train_loss = train_epoch(epoch, model, train_dataloader, optimizer, tokenizer, con)\n",
    "\n",
    "        # ê²€ì¦\n",
    "        valid_loss, valid_f1 = valid_epoch(epoch, valid_dataloader, model, tokenizer, con, small_id2label)\n",
    "\n",
    "        # í…ŒìŠ¤íŠ¸\n",
    "        test_loss, test_f1 = test_epoch(test_dataloader, model, tokenizer, con, small_id2label)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Summary:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "        print(f\"Valid F1: {valid_f1:.4f}, Test F1: {test_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/lhch9550/ê³µëª¨ì „/KPF-BERT-CLS/cls_model and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([58, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([58]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 341343\n",
      "Valid data size: 97533\n",
      "Test data size: 48786\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™” ë° DataLoader ì„¤ì •\n",
    "model, tokenizer = initialize_model(_config, small_label2id)\n",
    "optimizer = set_optimizer(model, _config)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "train_dataloader, valid_dataloader, test_dataloader = load_dataset(data, _config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ í˜¸ì¶œ\n",
    "train(model, tokenizer, train_dataloader, valid_dataloader, test_dataloader, optimizer, _config, small_id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved at: /home/lhch9550/ê³µëª¨ì „/KPF-BERT-CLS/saved_model\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, tokenizer, save_path):\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    print(f\"Model saved at: {save_path}\")\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ ê²½ë¡œ\n",
    "save_path = \"/home/lhch9550/ê³µëª¨ì „/KPF-BERT-CLS/saved_model\"\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ ì‹¤í–‰\n",
    "save_model(model, tokenizer, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11872/11872 [02:33<00:00, 77.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ìƒ˜í”Œ ë°ì´í„° ì •ë ¬ ê²€ì¦\n",
      "\n",
      "ğŸ“ Text: ì˜¤ ì‹œì¥ì€  ìš°ì„  ì£¼íƒê³µê¸‰ ì •ìƒí™”ë¥¼ ìœ„í•œ ì œë„ì  ê¸°ë°˜ì„ ì™„ë¹„í•˜ê³  ì‹ ì†í†µí•©ê¸°íšì„ ì ìš©í•œ ì¬ê°œë°œ ì¬ê±´ì¶• ì‚¬ì—…ì„ ì¡°ì†íˆ ì¶”ì§„í•˜ê² ë‹¤ ë©°  ë…¸í›„ ì €ì¸µ ì£¼ê±°ì§€ì—­ì„ ë¬¶ëŠ” ì†Œê·œëª¨ ì£¼íƒì •ë¹„ì‚¬ì—…ì¸ ëª¨ì•„ì£¼íƒ  ëª¨ì•„íƒ€ìš´ë„ ë”ìš± í™œì„±í™”í•˜ê² ë‹¤ ê³  ë§í–ˆë‹¤.\n",
      "âœ… True Label: ë¶€ë™ì‚°\n",
      "ğŸ”® Predicted Label: ëŸ¬ì‹œì•„\n",
      "\n",
      "ğŸ“ Text: ëŸ¬ì‹œì•„ ì–¸ë¡  ìŠ¤í¬ì¸  ìµìŠ¤í”„ë ˆìŠ¤ì— ë”°ë¥´ë©´ íŒ¬ë“¤ì´  ë²”ì¸ ìœ¼ë¡œ íŠ¹ì •í•œ ì„ ìˆ˜ëŠ” ë‹¤ë¦„ ì•„ë‹Œ ëŸ¬ì‹œì•„ì˜¬ë¦¼í”½ìœ„ì›íšŒ ROC ì˜ ì•ˆë“œë ˆì´ ëª¨ì˜ë ˆí”„ë‹¤.\n",
      "âœ… True Label: ì˜¬ë¦¼í”½_ì•„ì‹œì•ˆê²Œì„\n",
      "ğŸ”® Predicted Label: ëŸ¬ì‹œì•„\n",
      "\n",
      "ğŸ“ Text: ì˜ëŸ° ì¥ê´€ì€ í˜„ì¬ ë¯¸ ì¬ë¬´ì¥ê´€ì§ì„ ìˆ˜í–‰ì¤‘ì´ì§€ë§Œ  ë¯¸ ì—°ì¤€ ì´ì‚¬ì™€ ìƒŒí”„ë€ì‹œìŠ¤ì½” ì—°ë°©ì€í–‰ ì´ì¬  ì—°ì¤€ ì´ì‚¬íšŒ ë¶€ì˜ì¥ì„ ê±°ì³ ì—°ì¤€ ì´ì‚¬íšŒ ì˜ì¥ì„ ì§€ë‚¸ ì´ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤.\n",
      "âœ… True Label: ì™¸êµ\n",
      "ğŸ”® Predicted Label: ì™¸êµ\n",
      "\n",
      "ğŸ“ Text: ê²½ë‚¨ ê±°ì°½êµ°ì€ 13ì¼ë¶€í„° 22ì¼ê¹Œì§€ ì—´í˜ ê°„ ê±°ì°½ì°½í¬ì› ì¼ì›ì—ì„œ  ì œ3íšŒ ì•„ë¦¬ë¯¸ì•„ ê½ƒ ì¶•ì œ ë¥¼ ê°œìµœí•œë‹¤ê³  ë°í˜”ë‹¤.\n",
      "âœ… True Label: ìš”ë¦¬_ì—¬í–‰\n",
      "ğŸ”® Predicted Label: ì „ì‹œ_ê³µì—°\n",
      "\n",
      "ğŸ“ Text: LGì—”ì†”  ë‚´ì¼ ì½”ìŠ¤í”¼ ìƒì¥  ë”°ìƒ  ì„±ê³µí• ê¹Œ\n",
      "âœ… True Label: ì¦ê¶Œ_ì¦ì‹œ\n",
      "ğŸ”® Predicted Label: ëŸ¬ì‹œì•„\n",
      "\n",
      "[Classification Report]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ê³¨í”„     0.7356    0.8192    0.7752      1311\n",
      "       êµìœ¡_ì‹œí—˜     0.7490    0.5957    0.6636      4323\n",
      "        êµ­ì œê²½ì œ     0.0000    0.0000    0.0000      2471\n",
      "       êµ­íšŒ_ì •ë‹¹     0.5784    0.6919    0.6301     11735\n",
      "      ê¸ˆìœµ_ì¬í…Œí¬     0.0000    0.0000    0.0000      4892\n",
      "          ë‚ ì”¨     0.8525    0.7553    0.8010       421\n",
      "       ë…¸ë™_ë³µì§€     0.5797    0.6101    0.5945      2670\n",
      "       ë†êµ¬_ë°°êµ¬     0.6928    0.7969    0.7412      2708\n",
      "         ëŸ¬ì‹œì•„     0.0325    0.9168    0.0627      2487\n",
      "          ë¬´ì—­     0.0000    0.0000    0.0000      2390\n",
      "       ë¯¸êµ­_ë¶ë¯¸     0.0000    0.0000    0.0000      1789\n",
      "         ë¯¸ë””ì–´     0.4938    0.0999    0.1661       801\n",
      "       ë¯¸ìˆ _ê±´ì¶•     0.5904    0.2055    0.3048       842\n",
      "         ë°˜ë„ì²´     0.0000    0.0000    0.0000      1997\n",
      "       ë°©ì†¡_ì—°ì˜ˆ     0.7114    0.6856    0.6983      4729\n",
      "         ë¶€ë™ì‚°     0.0000    0.0000    0.0000      3636\n",
      "          ë¶í•œ     0.7328    0.6363    0.6811      2422\n",
      "       ì‚¬ê±´_ì‚¬ê³      0.7512    0.7693    0.7601      9123\n",
      "       ì‚°ì—…_ê¸°ì—…     0.0000    0.0000    0.0000      4568\n",
      "          ìƒí™œ     0.0000    0.0000    0.0000       160\n",
      "      ì„œë¹„ìŠ¤_ì‡¼í•‘     0.0000    0.0000    0.0000      2656\n",
      "          ì„ ê±°     0.6615    0.6368    0.6489      8945\n",
      "         ì•„ì‹œì•„     0.0000    0.0000    0.0000       716\n",
      "          ì—¬ì„±     0.5821    0.1716    0.2650      1364\n",
      "   ì˜¬ë¦¼í”½_ì•„ì‹œì•ˆê²Œì„     0.7228    0.4720    0.5711      2646\n",
      "          ì™¸êµ     0.4992    0.5335    0.5158      2343\n",
      "          ì™¸í™˜     0.0000    0.0000    0.0000      1489\n",
      "       ìš”ë¦¬_ì—¬í–‰     0.5518    0.2560    0.3498       832\n",
      "       ìœ ëŸ½_EU     0.0000    0.0000    0.0000      1794\n",
      "          ìœ í†µ     0.0000    0.0000    0.0000      6871\n",
      "          ìŒì•…     0.6124    0.3593    0.4529       796\n",
      "       ì˜ë£Œ_ê±´ê°•     0.7327    0.6579    0.6933      3154\n",
      "          ì¼ë³¸     0.0000    0.0000    0.0000       952\n",
      "         ìë™ì°¨     0.0000    0.0000    0.0000      4395\n",
      "          ìì›     0.0000    0.0000    0.0000      1940\n",
      "         ì¥ì• ì¸     0.6290    0.2838    0.3912       687\n",
      "       ì „ì‹œ_ê³µì—°     0.5358    0.6981    0.6063      5468\n",
      "          ì¢…êµ     0.6845    0.6364    0.6596       341\n",
      "          ì¤‘êµ­     0.0000    0.0000    0.0000      2250\n",
      "         ì¤‘ë‚¨ë¯¸     0.0000    0.0000    0.0000       349\n",
      "     ì¤‘ë™_ì•„í”„ë¦¬ì¹´     0.0000    0.0000    0.0000       202\n",
      "       ì¦ê¶Œ_ì¦ì‹œ     0.0000    0.0000    0.0000      4850\n",
      "         ì²­ì™€ëŒ€     0.5257    0.4445    0.4817      4940\n",
      "          ì¶œíŒ     0.2066    0.1158    0.1484       380\n",
      "       ì·¨ì—…_ì°½ì—…     0.0000    0.0000    0.0000     12875\n",
      "      í•™ìˆ _ë¬¸í™”ì¬     0.5935    0.4867    0.5348       600\n",
      "       í–‰ì •_ìì¹˜     0.4561    0.1179    0.1874      2425\n",
      "          í™˜ê²½     0.7528    0.3681    0.4945       728\n",
      "\n",
      "    accuracy                         0.3406    142463\n",
      "   macro avg     0.3385    0.2879    0.2892    142463\n",
      "weighted avg     0.3444    0.3406    0.3281    142463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhch9550/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def predict(model, tokenizer, test_dataloader, con, small_id2label):\n",
    "    model.eval()  # í‰ê°€ ëª¨ë“œ\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    texts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "            text_inputs = [str(text) for text in batch[0]]  # ì…ë ¥ í…ìŠ¤íŠ¸\n",
    "            encoded_inputs = tokenizer(text_inputs, padding=True, truncation=True, max_length=con.max_seq_len, return_tensors=\"pt\")\n",
    "            encoded_inputs = {k: v.to(con.device) for k, v in encoded_inputs.items()}\n",
    "            \n",
    "            outputs = model(**encoded_inputs)\n",
    "            logits = outputs.logits  # ì˜ˆì¸¡ê°’\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(batch[1].cpu().numpy())  # ì‹¤ì œ ì •ë‹µ\n",
    "            texts.extend(batch[0])  # ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥\n",
    "\n",
    "    # ë¼ë²¨ ID â†’ ë¼ë²¨ëª… ë³€í™˜\n",
    "    pred_labels = [small_id2label[p] for p in predictions]\n",
    "    true_labels = [small_id2label[t] for t in true_labels]\n",
    "\n",
    "    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df_results = pd.DataFrame({\"Text\": texts, \"True Label\": true_labels, \"Predicted Label\": pred_labels})\n",
    "\n",
    "    # ë²„ê¹…: ìƒ˜í”Œ 5ê°œ í™•ì¸ (ëœë¤)\n",
    "    sample_indices = random.sample(range(len(df_results)), 5)\n",
    "    print(\"\\nğŸ” ìƒ˜í”Œ ë°ì´í„° ì •ë ¬ ê²€ì¦\")\n",
    "    for idx in sample_indices:\n",
    "        print(f\"\\nğŸ“ Text: {df_results.iloc[idx]['Text']}\")\n",
    "        print(f\"True Label: {df_results.iloc[idx]['True Label']}\")\n",
    "        print(f\"Predicted Label: {df_results.iloc[idx]['Predicted Label']}\")\n",
    "\n",
    "    # ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ì¶œë ¥\n",
    "    print(\"\\n[Classification Report]\\n\")\n",
    "    print(classification_report(true_labels, pred_labels, digits=4))\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "saved_model_path = \"/home/lhch9550/ê³µëª¨ì „/KPF-BERT-CLS/saved_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(saved_model_path).to(_config.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
    "\n",
    "# ì¶”ë¡  ì‹¤í–‰\n",
    "df_results = predict(model, tokenizer, test_dataloader, _config, small_id2label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
